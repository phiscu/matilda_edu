{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90e24a2-d414-478d-81ad-4a69baf541d0",
   "metadata": {},
   "source": [
    "# MATILDA Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e3d49-e95d-435d-abe6-36de29ac20f6",
   "metadata": {},
   "source": [
    "After calibrating MATILDA we can now use the best parameter set to run the model with climate scenario data until 2100. In this notebook we will only\n",
    "\n",
    "- ...run MATILDA with the same parameters and settings but 2 x 31 different climate forcings.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> On a single CPU one MATILDA run over 120y takes ~4s. For all ensemble members this adds up to ~4min. The <code>MatildaBulkProcessor</code> class allows you to reduce this time significantly with more CPUs so you might want to run this notebook locally. Or have a coffee. Again...</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02dcda-b1a9-4e1b-b172-f0ab8e16f415",
   "metadata": {},
   "source": [
    "## Set up the scenario runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434caf4-d9da-4ae5-903e-d7facdd9e6c6",
   "metadata": {},
   "source": [
    "As before, we start by reading our paths from the `config.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582b6ee5-693a-401b-ac7b-1f69b04d739a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path: 'input/'\n",
      "Output path: 'output/'\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# get directories from config.ini\n",
    "dir_input = config['FILE_SETTINGS']['DIR_INPUT']\n",
    "dir_output = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "\n",
    "print(f\"Input path: '{dir_input}'\")\n",
    "print(f\"Output path: '{dir_output}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e4aa6-a290-4801-b3ac-318285c7822e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> We provide two storage options: <code>pickle</code> files are fast to read and write, but take up more disk space. You can use them on your local machine. <code>parquet</code> files are half the size but take longer to read and write. They should be your choice in the Binder.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcceea2-b3a9-46d5-a403-b274269d40ed",
   "metadata": {},
   "source": [
    "To run MATILDA for a period in the future, we need to adapt the modeling period. Therefore, we read the `settings.yaml` to a ditionary and change the respective settings. We also turn of the plotting module to reduce processing time and add the glacier profile from its `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe56f39-49b5-4c59-8a8d-662efd110483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings for MATILDA scenario runs:\n",
      "\n",
      "area_cat: 295.2763476500336\n",
      "area_glac: 31.81370047643339\n",
      "ele_cat: 3295.4765625\n",
      "ele_dat: 3337.7120334796778\n",
      "ele_glac: 4001.8798828125\n",
      "elev_rescaling: True\n",
      "freq: M\n",
      "lat: 42.1831077450328\n",
      "plot_type: all\n",
      "plots: False\n",
      "set_up_end: 1980-12-31\n",
      "set_up_start: 1979-01-01\n",
      "sim_end: 2100-12-31\n",
      "sim_start: 1981-01-01\n",
      "warn: False\n",
      "glacier_profile:      Elevation      Area          WE  EleZone\n",
      "0       1970.0  0.000000      0.0000     1900\n",
      "1       2000.0  0.000000      0.0000     2000\n",
      "2       2100.0  0.000000      0.0000     2100\n",
      "3       2200.0  0.000000      0.0000     2200\n",
      "4       2300.0  0.000000      0.0000     2300\n",
      "..         ...       ...         ...      ...\n",
      "156     4730.0  0.000023  20721.3700     4700\n",
      "157     4740.0  0.000013  14450.2180     4700\n",
      "158     4750.0  0.000006  10551.4730     4700\n",
      "159     4760.0  0.000000      0.0000     4700\n",
      "160     4780.0  0.000002   6084.7456     4700\n",
      "\n",
      "[161 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from tools.helpers import read_yaml, write_yaml\n",
    "import pandas as pd\n",
    "matilda_settings = read_yaml(f\"{dir_output}/settings.yml\")\n",
    "adapted_settings = {\n",
    "    \"set_up_start\": '1979-01-01',  # Start date of the setup period\n",
    "    \"set_up_end\": '1980-12-31',  # End date of the setup period\n",
    "    \"sim_start\": '1981-01-01',  # Start date of the simulation period\n",
    "    \"sim_end\": '2100-12-31',  # End date of the simulation period\n",
    "    \"plots\": False\n",
    "}\n",
    "matilda_settings['glacier_profile'] = pd.read_csv(f\"{dir_output}/glacier_profile.csv\")\n",
    "\n",
    "matilda_settings.update(adapted_settings)\n",
    "\n",
    "print(\"Settings for MATILDA scenario runs:\\n\")\n",
    "for key in matilda_settings.keys(): print(key + ': ' + str(matilda_settings[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82634a5-ddf1-4995-8245-ed980784e6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a3136-d477-437b-b45a-882326fb3269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32585d67-c797-4832-991d-21ffaff68b80",
   "metadata": {},
   "source": [
    "# Change to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c67329-f011-4190-a60e-07caa7cf8146",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9057b1cd-feb2-438f-bde6-265a7af013f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = read_yaml(f\"{dir_output}/parameters.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b272ac4-724c-401b-8ace-86a31b94aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.helpers import pickle_to_dict\n",
    "\n",
    "## Read adjusted CMIP6 data\n",
    "tas = pickle_to_dict(f\"{dir_output}cmip6/adjusted/tas.pickle\")\n",
    "pr = pickle_to_dict(f\"{dir_output}cmip6/adjusted/pr.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d96951-e6fd-41c7-9cd8-a768934684c0",
   "metadata": {},
   "source": [
    "# Continue here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8035f9-98c5-419b-b3a6-b922f4a10d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmip2df(temp, prec, scen, col):\n",
    "    \"\"\"\n",
    "    Converts temperature and precipitation data from a CMIP model output dictionary into a Pandas DataFrame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    temp : dict\n",
    "        dictionary of temperature data from a CMIP model\n",
    "    prec : dict\n",
    "        dictionary of precipitation data from a CMIP model\n",
    "    scen : str\n",
    "        name of the scenario (e.g. RCP4.5)\n",
    "    col : str\n",
    "        name of the column containing data for the scenario (e.g. tas)\n",
    "    Returns:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the temperature and precipitation data for the given scenario and column\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'T2': temp[scen][col], 'RRR': prec[scen][col]}).reset_index()\n",
    "    df.columns = ['TIMESTAMP', 'T2', 'RRR']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6967a309-7dec-4b81-971c-aacb0d541e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create MATILDA input\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_scenario_dict(tas: dict, pr: dict, scenario_nums: list) -> dict:\n",
    "    \"\"\"\n",
    "    Create a nested dictionary of scenarios and models from two dictionaries of pandas DataFrames.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tas : dict\n",
    "        A dictionary of pandas DataFrames where the keys are scenario names and each DataFrame has columns\n",
    "        representing different climate model mean daily temperature (K) time series.\n",
    "    pr : dict\n",
    "        A dictionary of pandas DataFrames where the keys are scenario names and each DataFrame has columns\n",
    "        representing different climate models mean daily precipitation (mm/day) time series.\n",
    "    scenario_nums : list\n",
    "        A list of integers representing the scenario numbers to include in the resulting dictionary.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A nested dictionary where the top-level keys are scenario names (e.g. 'SSP2', 'SSP5') and the values are\n",
    "        dictionaries containing climate models as keys and the corresponding pandas DataFrames as values.\n",
    "        The DataFrames have three columns: 'TIMESTAMP', 'T2', and 'RRR', where 'TIMESTAMP'\n",
    "        represents the time step, 'T2' represents the mean daily temperature (K), and 'RRR' represents the mean\n",
    "        daily precipitation (mm/day).\n",
    "    \"\"\"\n",
    "    scenarios = {}\n",
    "    for s in scenario_nums:\n",
    "        s = 'SSP' + str(s)\n",
    "        scenarios[s] = {}\n",
    "        for m in tas[s].columns:\n",
    "            model = pd.DataFrame({'T2': tas[s][m],\n",
    "                                  'RRR': pr[s][m]})\n",
    "            model = model.reset_index()\n",
    "            mod_dict = {m: model.rename(columns={'time': 'TIMESTAMP'})}\n",
    "            scenarios[s].update(mod_dict)\n",
    "    return scenarios\n",
    "\n",
    "scenarios = create_scenario_dict(tas, pr, [2, 5])\n",
    "dict_to_pickle(scenarios, test_dir + 'adjusted/matilda_input.pickle')\n",
    "\n",
    "# scenarios = pickle_to_dict(test_dir + 'adjusted/matilda_input.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f082b4d-db3d-437f-9be7-b141d13d4aba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scenarios SSP2 and SSP5: 100%|███████████████████| 2/2 [04:33<00:00, 136.91s/it]\n"
     ]
    }
   ],
   "source": [
    "## Run Matilda in a loop (takes a while - have a coffee)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import contextlib\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class MatildaBulkProcessor:\n",
    "    \"\"\"\n",
    "    A class to run multiple MATILDA simulations for different input scenarios and models in single or multi-processing\n",
    "    mode and store the results in a dictionary.\n",
    "    Attributes\n",
    "    ----------\n",
    "    scenarios : dict\n",
    "        A dictionary with scenario names as keys and a dictionary of climate models as values.\n",
    "    matilda_settings : dict\n",
    "        A dictionary of MATILDA settings.\n",
    "    matilda_parameters : dict\n",
    "        A dictionary of MATILDA parameter values.\n",
    "    Methods\n",
    "    -------\n",
    "    run_single_process():\n",
    "        Runs the MATILDA simulations for the scenarios and models in single-processing mode and returns a dictionary\n",
    "        of results.\n",
    "    run_multi_process():\n",
    "        Runs the MATILDA simulations for the scenarios and models in multi-processing mode and returns a dictionary\n",
    "        of results.\n",
    "    matilda_headless(df, matilda_settings, matilda_parameters):\n",
    "        A helper function to run a single MATILDA simulation given a dataframe, MATILDA settings and parameter\n",
    "        values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scenarios, matilda_settings, matilda_parameters):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        scenarios : dict\n",
    "            A dictionary with scenario names as keys and a dictionary of models as values.\n",
    "        matilda_settings : dict\n",
    "            A dictionary of MATILDA settings.\n",
    "        matilda_parameters : dict\n",
    "            A dictionary of MATILDA parameter values.\n",
    "        \"\"\"\n",
    "\n",
    "        self.scenarios = scenarios\n",
    "        self.matilda_settings = matilda_settings\n",
    "        self.matilda_parameters = matilda_parameters\n",
    "\n",
    "    @staticmethod\n",
    "    def matilda_headless(df, matilda_settings, matilda_parameters):\n",
    "        \"\"\"\n",
    "        A helper function to run a single MATILDA simulation given a dataframe, MATILDA settings and parameter\n",
    "        values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            The input dataframe for the MATILDA simulation.\n",
    "        matilda_settings : dict\n",
    "            A dictionary of MATILDA settings.\n",
    "        matilda_parameters : dict\n",
    "            A dictionary of MATILDA parameter values.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing the MATILDA model output and glacier rescaling factor.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(os.devnull, 'w') as devnull:\n",
    "            with contextlib.redirect_stdout(devnull):\n",
    "                output = matilda_simulation(df, **matilda_settings, parameter_set=matilda_parameters)\n",
    "        return {'model_output': output[0], 'glacier_rescaling': output[5]}\n",
    "\n",
    "    def run_single_process(self):\n",
    "        \"\"\"\n",
    "        Runs the MATILDA simulations for the scenarios and models in single-processing mode and returns a dictionary\n",
    "        of results.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of MATILDA simulation results.\n",
    "        \"\"\"\n",
    "\n",
    "        out_dict = {}  # Create an empty dictionary to store the outputs\n",
    "        # Loop over the scenarios with progress bar\n",
    "        for scenario in self.scenarios.keys():\n",
    "            model_dict = {}  # Create an empty dictionary to store the model outputs\n",
    "            # Loop over the models with progress bar\n",
    "            for model in tqdm(self.scenarios[scenario].keys(), desc=scenario):\n",
    "                # Get the dataframe for the current scenario and model\n",
    "                df = self.scenarios[scenario][model]\n",
    "                # Run the model simulation and get the output while suppressing prints\n",
    "                model_output = self.matilda_headless(df, self.matilda_settings, self.matilda_parameters)\n",
    "                # Store the list of output in the model dictionary\n",
    "                model_dict[model] = model_output\n",
    "            # Store the model dictionary in the scenario dictionary\n",
    "            out_dict[scenario] = model_dict\n",
    "        return out_dict\n",
    "\n",
    "    def run_multi_process(self):\n",
    "        \"\"\"\n",
    "        Runs the MATILDA simulations for the scenarios and models in multi-processing mode and returns a dictionary\n",
    "        of results.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of MATILDA simulation results.\n",
    "        \"\"\"\n",
    "\n",
    "        out_dict = {}  # Create an empty dictionary to store the outputs\n",
    "        with Pool() as pool:\n",
    "            # Loop over the scenarios with progress bar\n",
    "            for scenario in tqdm(self.scenarios.keys(), desc=\"Scenarios SSP2 and SSP5\"):\n",
    "                model_dict = {}  # Create an empty dictionary to store the model outputs\n",
    "                # Loop over the models with progress bar\n",
    "                model_list = [self.scenarios[scenario][m] for m in self.scenarios[scenario].keys()]\n",
    "                for model, model_output in zip(self.scenarios[scenario], pool.map(\n",
    "                        partial(self.matilda_headless, matilda_settings=self.matilda_settings,\n",
    "                                matilda_parameters=self.matilda_parameters), model_list)):\n",
    "                    model_dict[model] = model_output\n",
    "                # Store the model dictionary in the scenario dictionary\n",
    "                out_dict[scenario] = model_dict\n",
    "            pool.close()\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "\n",
    "matilda_bulk = MatildaBulkProcessor(scenarios, matilda_settings, param_dict)\n",
    "# matilda_scenarios = matilda_bulk.run_single_process()\n",
    "matilda_scenarios = matilda_bulk.run_multi_process()\n",
    "\n",
    "dict_to_pickle(matilda_scenarios, test_dir + 'adjusted/matilda_scenarios.pickle')\n",
    "\n",
    "# matilda_scenarios = pickle_to_dict(test_dir + 'adjusted/matilda_scenarios.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d42cd0-2306-449a-9b43-4c6efd0cc917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing parquet files: 100%|██████████████████████| 2/2 [00:20<00:00, 10.37s/it]\n",
      "Reading parquet files: 100%|██████████████████████| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "## Store results in parquet files to limit storage costs\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastparquet import write\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def dict_to_parquet(dictionary: dict, directory_path: str, pbar: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Recursively stores the dataframes in the input dictionary as parquet files in the specified directory.\n",
    "    Nested dictionaries are supported. If the specified directory does not exist, it will be created.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        A nested dictionary containing pandas dataframes.\n",
    "    directory_path : str\n",
    "        The directory path to store the parquet files.\n",
    "    pbar : bool, optional\n",
    "        A flag indicating whether to display a progress bar. Default is True.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "    if pbar:\n",
    "        bar_iter = tqdm(dictionary.items(), desc='Writing parquet files: ')\n",
    "    else:\n",
    "        bar_iter = dictionary.items()\n",
    "    for k, v in bar_iter:\n",
    "        if isinstance(v, dict):\n",
    "            dict_to_parquet(v, os.path.join(directory_path, k), pbar=False)\n",
    "        else:\n",
    "            file_path = os.path.join(directory_path, k + \".parquet\")\n",
    "            write(file_path, v, compression='GZIP')\n",
    "\n",
    "\n",
    "def parquet_to_dict(directory_path: str, pbar: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Recursively loads the dataframes from the parquet files in the specified directory and returns a dictionary.\n",
    "    Nested directories are supported.\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_path : str\n",
    "        The directory path containing the parquet files.\n",
    "    pbar : bool, optional\n",
    "        A flag indicating whether to display a progress bar. Default is True.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the loaded pandas dataframes.\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    if pbar:\n",
    "        bar_iter = tqdm(sorted(os.listdir(directory_path)), desc='Reading parquet files: ')\n",
    "    else:\n",
    "        bar_iter = sorted(os.listdir(directory_path))\n",
    "    for file_name in bar_iter:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isdir(file_path):\n",
    "            dictionary[file_name] = parquet_to_dict(file_path, pbar=False)\n",
    "        elif file_name.endswith(\".parquet\"):\n",
    "            k = file_name[:-len(\".parquet\")]\n",
    "            dictionary[k] = pd.read_parquet(file_path)\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "# Store dictionary in Parquet files\n",
    "dict_to_parquet(matilda_scenarios, test_dir + 'adjusted/parquet')\n",
    "# Load dictionary from Parquet files\n",
    "matilda_scenarios = parquet_to_dict(test_dir + 'adjusted/parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcda2bc-d73d-4a16-b162-64480188eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCESS-CM2</th>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <th>CESM2</th>\n",
       "      <th>CESM2-WACCM</th>\n",
       "      <th>CMCC-CM2-SR5</th>\n",
       "      <th>CMCC-ESM2</th>\n",
       "      <th>CNRM-CM6-1</th>\n",
       "      <th>CNRM-ESM2-1</th>\n",
       "      <th>CanESM5</th>\n",
       "      <th>...</th>\n",
       "      <th>KACE-1-0-G</th>\n",
       "      <th>KIOST-ESM</th>\n",
       "      <th>MIROC-ES2L</th>\n",
       "      <th>MIROC6</th>\n",
       "      <th>MPI-ESM1-2-HR</th>\n",
       "      <th>MPI-ESM1-2-LR</th>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <th>NESM3</th>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <th>UKESM1-0-LL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-12-31</th>\n",
       "      <td>489.219627</td>\n",
       "      <td>595.058029</td>\n",
       "      <td>346.821137</td>\n",
       "      <td>629.315532</td>\n",
       "      <td>578.142931</td>\n",
       "      <td>563.517190</td>\n",
       "      <td>746.864899</td>\n",
       "      <td>578.373783</td>\n",
       "      <td>703.129751</td>\n",
       "      <td>536.197463</td>\n",
       "      <td>...</td>\n",
       "      <td>398.984865</td>\n",
       "      <td>701.444736</td>\n",
       "      <td>446.305468</td>\n",
       "      <td>143.678270</td>\n",
       "      <td>476.890545</td>\n",
       "      <td>137.049389</td>\n",
       "      <td>554.900912</td>\n",
       "      <td>290.756861</td>\n",
       "      <td>576.131687</td>\n",
       "      <td>681.752345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-12-31</th>\n",
       "      <td>652.972977</td>\n",
       "      <td>681.485047</td>\n",
       "      <td>453.904854</td>\n",
       "      <td>653.164449</td>\n",
       "      <td>695.314827</td>\n",
       "      <td>615.249419</td>\n",
       "      <td>628.733465</td>\n",
       "      <td>477.512990</td>\n",
       "      <td>665.219233</td>\n",
       "      <td>698.445654</td>\n",
       "      <td>...</td>\n",
       "      <td>476.225167</td>\n",
       "      <td>464.201889</td>\n",
       "      <td>573.875621</td>\n",
       "      <td>385.559960</td>\n",
       "      <td>528.778428</td>\n",
       "      <td>519.109059</td>\n",
       "      <td>521.157326</td>\n",
       "      <td>489.860012</td>\n",
       "      <td>602.291544</td>\n",
       "      <td>748.047617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-12-31</th>\n",
       "      <td>619.680708</td>\n",
       "      <td>590.854720</td>\n",
       "      <td>477.595450</td>\n",
       "      <td>691.240057</td>\n",
       "      <td>755.362363</td>\n",
       "      <td>608.752965</td>\n",
       "      <td>642.878796</td>\n",
       "      <td>553.391766</td>\n",
       "      <td>661.916801</td>\n",
       "      <td>438.211426</td>\n",
       "      <td>...</td>\n",
       "      <td>532.132902</td>\n",
       "      <td>333.981245</td>\n",
       "      <td>484.701611</td>\n",
       "      <td>558.510751</td>\n",
       "      <td>812.636811</td>\n",
       "      <td>663.039360</td>\n",
       "      <td>370.546618</td>\n",
       "      <td>503.755533</td>\n",
       "      <td>764.764122</td>\n",
       "      <td>787.952487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31</th>\n",
       "      <td>794.595243</td>\n",
       "      <td>523.181282</td>\n",
       "      <td>604.361125</td>\n",
       "      <td>580.936525</td>\n",
       "      <td>758.916001</td>\n",
       "      <td>527.498612</td>\n",
       "      <td>607.489740</td>\n",
       "      <td>449.989307</td>\n",
       "      <td>500.299186</td>\n",
       "      <td>677.531880</td>\n",
       "      <td>...</td>\n",
       "      <td>719.125083</td>\n",
       "      <td>482.652626</td>\n",
       "      <td>289.495486</td>\n",
       "      <td>672.657340</td>\n",
       "      <td>631.766449</td>\n",
       "      <td>303.580676</td>\n",
       "      <td>477.272085</td>\n",
       "      <td>440.321661</td>\n",
       "      <td>683.011302</td>\n",
       "      <td>652.502181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096-12-31</th>\n",
       "      <td>-1288.241220</td>\n",
       "      <td>-1480.041790</td>\n",
       "      <td>-1016.812152</td>\n",
       "      <td>-2061.202811</td>\n",
       "      <td>-1968.941241</td>\n",
       "      <td>-2191.861098</td>\n",
       "      <td>-2449.393345</td>\n",
       "      <td>-2299.754660</td>\n",
       "      <td>-2012.954531</td>\n",
       "      <td>-4251.593032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1090.486306</td>\n",
       "      <td>-1371.340935</td>\n",
       "      <td>-897.186068</td>\n",
       "      <td>-1881.141381</td>\n",
       "      <td>-1832.277070</td>\n",
       "      <td>-1291.982653</td>\n",
       "      <td>-1453.510423</td>\n",
       "      <td>-2162.443748</td>\n",
       "      <td>-1564.078466</td>\n",
       "      <td>-2387.043753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097-12-31</th>\n",
       "      <td>-2571.083660</td>\n",
       "      <td>-1480.781704</td>\n",
       "      <td>-1139.836004</td>\n",
       "      <td>-2078.627509</td>\n",
       "      <td>-1801.911132</td>\n",
       "      <td>-2627.467176</td>\n",
       "      <td>-2239.858493</td>\n",
       "      <td>-2152.262625</td>\n",
       "      <td>-1825.224447</td>\n",
       "      <td>-3623.903549</td>\n",
       "      <td>...</td>\n",
       "      <td>-2045.047084</td>\n",
       "      <td>-2526.697419</td>\n",
       "      <td>-974.421717</td>\n",
       "      <td>-1679.069329</td>\n",
       "      <td>-859.242379</td>\n",
       "      <td>-1769.975810</td>\n",
       "      <td>-1385.699596</td>\n",
       "      <td>-2360.782662</td>\n",
       "      <td>-1453.575313</td>\n",
       "      <td>-2293.768224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098-12-31</th>\n",
       "      <td>-1941.220928</td>\n",
       "      <td>-1792.655160</td>\n",
       "      <td>-1906.818454</td>\n",
       "      <td>-2251.967257</td>\n",
       "      <td>-1743.845374</td>\n",
       "      <td>-1461.817427</td>\n",
       "      <td>-2157.611726</td>\n",
       "      <td>-2439.343272</td>\n",
       "      <td>-2084.710186</td>\n",
       "      <td>-3216.436004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1483.458857</td>\n",
       "      <td>-1368.052391</td>\n",
       "      <td>-2067.970254</td>\n",
       "      <td>-1972.841972</td>\n",
       "      <td>-1281.312149</td>\n",
       "      <td>-1318.289899</td>\n",
       "      <td>-1558.632339</td>\n",
       "      <td>-1075.030866</td>\n",
       "      <td>-1566.479434</td>\n",
       "      <td>-2506.163565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099-12-31</th>\n",
       "      <td>-2436.369518</td>\n",
       "      <td>-1982.526982</td>\n",
       "      <td>-1075.516051</td>\n",
       "      <td>-1692.580493</td>\n",
       "      <td>-2312.576369</td>\n",
       "      <td>-1563.180834</td>\n",
       "      <td>-2376.998974</td>\n",
       "      <td>-2028.512625</td>\n",
       "      <td>-2289.604763</td>\n",
       "      <td>-3963.892992</td>\n",
       "      <td>...</td>\n",
       "      <td>-1331.042008</td>\n",
       "      <td>-1888.471132</td>\n",
       "      <td>-2300.166545</td>\n",
       "      <td>-1741.934115</td>\n",
       "      <td>-1139.945274</td>\n",
       "      <td>-1228.108574</td>\n",
       "      <td>-1027.212287</td>\n",
       "      <td>-1855.479335</td>\n",
       "      <td>-1773.241578</td>\n",
       "      <td>-2713.824498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31</th>\n",
       "      <td>-2416.179970</td>\n",
       "      <td>-1732.514015</td>\n",
       "      <td>-1892.541574</td>\n",
       "      <td>-1794.611666</td>\n",
       "      <td>-1585.368051</td>\n",
       "      <td>-2175.146251</td>\n",
       "      <td>-2946.806723</td>\n",
       "      <td>-2664.010744</td>\n",
       "      <td>-1580.986566</td>\n",
       "      <td>-4077.191461</td>\n",
       "      <td>...</td>\n",
       "      <td>-1800.969124</td>\n",
       "      <td>-1716.115835</td>\n",
       "      <td>-964.129898</td>\n",
       "      <td>-1786.428259</td>\n",
       "      <td>-1684.737978</td>\n",
       "      <td>-1745.614368</td>\n",
       "      <td>-1513.818200</td>\n",
       "      <td>-1952.698892</td>\n",
       "      <td>-1915.638167</td>\n",
       "      <td>-2959.967230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACCESS-CM2  ACCESS-ESM1-5  BCC-CSM2-MR        CESM2  CESM2-WACCM  \\\n",
       "TIMESTAMP                                                                       \n",
       "1980-12-31     0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "1981-12-31   489.219627     595.058029   346.821137   629.315532   578.142931   \n",
       "1982-12-31   652.972977     681.485047   453.904854   653.164449   695.314827   \n",
       "1983-12-31   619.680708     590.854720   477.595450   691.240057   755.362363   \n",
       "1984-12-31   794.595243     523.181282   604.361125   580.936525   758.916001   \n",
       "...                 ...            ...          ...          ...          ...   \n",
       "2096-12-31 -1288.241220   -1480.041790 -1016.812152 -2061.202811 -1968.941241   \n",
       "2097-12-31 -2571.083660   -1480.781704 -1139.836004 -2078.627509 -1801.911132   \n",
       "2098-12-31 -1941.220928   -1792.655160 -1906.818454 -2251.967257 -1743.845374   \n",
       "2099-12-31 -2436.369518   -1982.526982 -1075.516051 -1692.580493 -2312.576369   \n",
       "2100-12-31 -2416.179970   -1732.514015 -1892.541574 -1794.611666 -1585.368051   \n",
       "\n",
       "            CMCC-CM2-SR5    CMCC-ESM2   CNRM-CM6-1  CNRM-ESM2-1      CanESM5  \\\n",
       "TIMESTAMP                                                                      \n",
       "1980-12-31      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1981-12-31    563.517190   746.864899   578.373783   703.129751   536.197463   \n",
       "1982-12-31    615.249419   628.733465   477.512990   665.219233   698.445654   \n",
       "1983-12-31    608.752965   642.878796   553.391766   661.916801   438.211426   \n",
       "1984-12-31    527.498612   607.489740   449.989307   500.299186   677.531880   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "2096-12-31  -2191.861098 -2449.393345 -2299.754660 -2012.954531 -4251.593032   \n",
       "2097-12-31  -2627.467176 -2239.858493 -2152.262625 -1825.224447 -3623.903549   \n",
       "2098-12-31  -1461.817427 -2157.611726 -2439.343272 -2084.710186 -3216.436004   \n",
       "2099-12-31  -1563.180834 -2376.998974 -2028.512625 -2289.604763 -3963.892992   \n",
       "2100-12-31  -2175.146251 -2946.806723 -2664.010744 -1580.986566 -4077.191461   \n",
       "\n",
       "            ...   KACE-1-0-G    KIOST-ESM   MIROC-ES2L       MIROC6  \\\n",
       "TIMESTAMP   ...                                                       \n",
       "1980-12-31  ...     0.000000     0.000000     0.000000     0.000000   \n",
       "1981-12-31  ...   398.984865   701.444736   446.305468   143.678270   \n",
       "1982-12-31  ...   476.225167   464.201889   573.875621   385.559960   \n",
       "1983-12-31  ...   532.132902   333.981245   484.701611   558.510751   \n",
       "1984-12-31  ...   719.125083   482.652626   289.495486   672.657340   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "2096-12-31  ... -1090.486306 -1371.340935  -897.186068 -1881.141381   \n",
       "2097-12-31  ... -2045.047084 -2526.697419  -974.421717 -1679.069329   \n",
       "2098-12-31  ... -1483.458857 -1368.052391 -2067.970254 -1972.841972   \n",
       "2099-12-31  ... -1331.042008 -1888.471132 -2300.166545 -1741.934115   \n",
       "2100-12-31  ... -1800.969124 -1716.115835  -964.129898 -1786.428259   \n",
       "\n",
       "            MPI-ESM1-2-HR  MPI-ESM1-2-LR   MRI-ESM2-0        NESM3  \\\n",
       "TIMESTAMP                                                            \n",
       "1980-12-31       0.000000       0.000000     0.000000     0.000000   \n",
       "1981-12-31     476.890545     137.049389   554.900912   290.756861   \n",
       "1982-12-31     528.778428     519.109059   521.157326   489.860012   \n",
       "1983-12-31     812.636811     663.039360   370.546618   503.755533   \n",
       "1984-12-31     631.766449     303.580676   477.272085   440.321661   \n",
       "...                   ...            ...          ...          ...   \n",
       "2096-12-31   -1832.277070   -1291.982653 -1453.510423 -2162.443748   \n",
       "2097-12-31    -859.242379   -1769.975810 -1385.699596 -2360.782662   \n",
       "2098-12-31   -1281.312149   -1318.289899 -1558.632339 -1075.030866   \n",
       "2099-12-31   -1139.945274   -1228.108574 -1027.212287 -1855.479335   \n",
       "2100-12-31   -1684.737978   -1745.614368 -1513.818200 -1952.698892   \n",
       "\n",
       "             NorESM2-MM  UKESM1-0-LL  \n",
       "TIMESTAMP                             \n",
       "1980-12-31     0.000000     0.000000  \n",
       "1981-12-31   576.131687   681.752345  \n",
       "1982-12-31   602.291544   748.047617  \n",
       "1983-12-31   764.764122   787.952487  \n",
       "1984-12-31   683.011302   652.502181  \n",
       "...                 ...          ...  \n",
       "2096-12-31 -1564.078466 -2387.043753  \n",
       "2097-12-31 -1453.575313 -2293.768224  \n",
       "2098-12-31 -1566.479434 -2506.163565  \n",
       "2099-12-31 -1773.241578 -2713.824498  \n",
       "2100-12-31 -1915.638167 -2959.967230  \n",
       "\n",
       "[121 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create custom dataframes for analysis\n",
    "\n",
    "def custom_df(dic, scenario, var, resample_freq=None):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of model outputs and returns a combined dataframe of a specific variable for a given scenario.\n",
    "    Parameters\n",
    "    -------\n",
    "    dic : dict\n",
    "        A nested dictionary of model outputs.\n",
    "        The outer keys are scenario names and the inner keys are model names.\n",
    "        The corresponding values are dictionaries containing two keys:\n",
    "        'model_output' (DataFrame): containing model outputs for a given scenario and model\n",
    "        'glacier_rescaling' (DataFrame): containing glacier properties for a given scenario and model\n",
    "    scenario : str\n",
    "        The name of the scenario to select from the dictionary.\n",
    "    var : str\n",
    "        The name of the variable to extract from the model output DataFrame.\n",
    "    resample_freq : str, optional\n",
    "        The frequency of the resulting time series data.\n",
    "        Defaults to None (i.e. no resampling).\n",
    "        If provided, should be in pandas resample frequency string format.\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the combined data of the specified variable for the selected scenario\n",
    "        and models. The DataFrame is indexed by the time steps of the original models.\n",
    "        The columns are the names of the models in the selected scenario.\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError\n",
    "        If the provided  var  string is not one of the following: ['avg_temp_catchment', 'avg_temp_glaciers',\n",
    "        'evap_off_glaciers', 'prec_off_glaciers', 'prec_on_glaciers', 'rain_off_glaciers', 'snow_off_glaciers',\n",
    "        'rain_on_glaciers', 'snow_on_glaciers', 'snowpack_off_glaciers', 'soil_moisture', 'upper_groundwater',\n",
    "        'lower_groundwater', 'melt_off_glaciers', 'melt_on_glaciers', 'ice_melt_on_glaciers', 'snow_melt_on_glaciers',\n",
    "        'refreezing_ice', 'refreezing_snow', 'total_refreezing', 'SMB', 'actual_evaporation', 'total_precipitation',\n",
    "        'total_melt', 'runoff_without_glaciers', 'runoff_from_glaciers', 'total_runoff', 'glacier_area',\n",
    "        'glacier_elev', 'smb_water_year', 'smb_scaled', 'smb_scaled_capped', 'smb_scaled_capped_cum', 'surplus']\n",
    "    \"\"\"\n",
    "    out1_cols = ['avg_temp_catchment', 'avg_temp_glaciers', 'evap_off_glaciers',\n",
    "                 'prec_off_glaciers', 'prec_on_glaciers', 'rain_off_glaciers',\n",
    "                 'snow_off_glaciers', 'rain_on_glaciers', 'snow_on_glaciers',\n",
    "                 'snowpack_off_glaciers', 'soil_moisture', 'upper_groundwater',\n",
    "                 'lower_groundwater', 'melt_off_glaciers', 'melt_on_glaciers',\n",
    "                 'ice_melt_on_glaciers', 'snow_melt_on_glaciers', 'refreezing_ice',\n",
    "                 'refreezing_snow', 'total_refreezing', 'SMB', 'actual_evaporation',\n",
    "                 'total_precipitation', 'total_melt', 'runoff_without_glaciers',\n",
    "                 'runoff_from_glaciers', 'total_runoff']\n",
    "\n",
    "    out2_cols = ['glacier_area', 'glacier_elev', 'smb_water_year',\n",
    "                 'smb_scaled', 'smb_scaled_capped', 'smb_scaled_capped_cum',\n",
    "                 'surplus']\n",
    "\n",
    "    if var in out1_cols:\n",
    "        output_df = 'model_output'\n",
    "    elif var in out2_cols:\n",
    "        output_df = 'glacier_rescaling'\n",
    "    else:\n",
    "        raise ValueError(\"var needs to be one of the following strings: \" +\n",
    "                         str([out1_cols, out2_cols]))\n",
    "\n",
    "    # Create an empty list to store the dataframes\n",
    "    dfs = []\n",
    "    # Loop over the models in the selected scenario\n",
    "    for model in dic[scenario].keys():\n",
    "        # Get the dataframe for the current model\n",
    "        df = dic[scenario][model][output_df]\n",
    "        # Append the dataframe to the list of dataframes\n",
    "        dfs.append(df[var])\n",
    "    # Concatenate the dataframes into a single dataframe\n",
    "    combined_df = pd.concat(dfs, axis=1)\n",
    "    # Set the column names of the combined dataframe to the model names\n",
    "    combined_df.columns = dic[scenario].keys()\n",
    "    # Resample time series\n",
    "    if resample_freq is not None:\n",
    "        if output_df == 'glacier_rescaling':\n",
    "            if var in ['glacier_area', 'glacier_elev']:\n",
    "                combined_df = combined_df.resample(resample_freq).mean()\n",
    "            else:\n",
    "                combined_df = combined_df.resample(resample_freq).sum()\n",
    "        else:\n",
    "            if var in ['avg_temp_catchment', 'avg_temp_glaciers']:\n",
    "                combined_df = combined_df.resample(resample_freq).mean()\n",
    "            else:\n",
    "                combined_df = combined_df.resample(resample_freq).sum()\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "custom_df(matilda_scenarios, scenario='SSP5', var='smb_water_year', resample_freq='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e41f2a-7bba-4686-b3c7-256b04917cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
