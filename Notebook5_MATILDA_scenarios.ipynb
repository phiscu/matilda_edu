{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90e24a2-d414-478d-81ad-4a69baf541d0",
   "metadata": {},
   "source": [
    "# MATILDA Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e3d49-e95d-435d-abe6-36de29ac20f6",
   "metadata": {},
   "source": [
    "After calibrating MATILDA we can now use the best parameter set to run the model with climate scenario data until 2100. In this notebook we will only\n",
    "\n",
    "- ...run MATILDA with the same parameters and settings but 2 x 31 different climate forcings.\n",
    "\n",
    "**Note:** On a single CPU one MATILDA run over 120y takes ~4s. For all ensemble members this adds up to ~4min. The `MatildaBulkProcessor` class allows you to reduce this time significantly with more CPUs so you might want to run this notebook locally. Or have a coffee. Again...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a1f03-fc63-4625-b04a-a80cd54c13a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8035f9-98c5-419b-b3a6-b922f4a10d0a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from matilda.core import matilda_simulation\n",
    "\n",
    "home = str(Path.home()) + '/Seafile'\n",
    "sys.path.append(home + '/Ana-Lena_Phillip/data/tests_and_tools')\n",
    "wd = home + '/EBA-CA/Papers/No1_Kysylsuu_Bash-Kaingdy/data'\n",
    "glacier_profile = pd.read_csv(wd + \"/kyzulsuu_glacier_profile.csv\")\n",
    "\n",
    "test_dir = '/home/phillip/Seafile/EBA-CA/Repositories/matilda_edu/output/cmip6/'\n",
    "\n",
    "\n",
    "def dict_to_pickle(dic, target_path):\n",
    "    \"\"\"\n",
    "    Saves a dictionary to a pickle file at the specified target path.\n",
    "    Creates target directory if not existing.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dic : dict\n",
    "        The dictionary to save to a pickle file.\n",
    "    target_path : str\n",
    "        The path of the file where the dictionary shall be stored.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    target_dir = os.path.dirname(target_path)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    with open(target_path, 'wb') as f:\n",
    "        pickle.dump(dic, f)\n",
    "\n",
    "\n",
    "def pickle_to_dict(file_path):\n",
    "    \"\"\"\n",
    "    Loads a dictionary from a pickle file at a specified file path.\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The path of the pickle file to load.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The dictionary loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        dic = pickle.load(f)\n",
    "    return dic\n",
    "\n",
    "\n",
    "def cmip2df(temp, prec, scen, col):\n",
    "    \"\"\"\n",
    "    Converts temperature and precipitation data from a CMIP model output dictionary into a Pandas DataFrame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    temp : dict\n",
    "        dictionary of temperature data from a CMIP model\n",
    "    prec : dict\n",
    "        dictionary of precipitation data from a CMIP model\n",
    "    scen : str\n",
    "        name of the scenario (e.g. RCP4.5)\n",
    "    col : str\n",
    "        name of the column containing data for the scenario (e.g. tas)\n",
    "    Returns:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the temperature and precipitation data for the given scenario and column\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'T2': temp[scen][col], 'RRR': prec[scen][col]}).reset_index()\n",
    "    df.columns = ['TIMESTAMP', 'T2', 'RRR']\n",
    "    return df\n",
    "\n",
    "\n",
    "matilda_settings = {\n",
    "    \"set_up_start\": '1979-01-01',  # Start date of the setup period\n",
    "    \"set_up_end\": '1980-12-31',  # End date of the setup period\n",
    "    \"sim_start\": '1981-01-01',  # Start date of the simulation period\n",
    "    \"sim_end\": '2100-12-31',  # End date of the simulation period\n",
    "    \"freq\": \"M\",  # Frequency of the data (monthly)\n",
    "    \"glacier_profile\": glacier_profile,  # Glacier profile\n",
    "    \"area_cat\": 295.763,  # Area of the catchment\n",
    "    \"lat\": 42.33,  # Latitude of the catchment\n",
    "    \"warn\": False,  # Warning flag\n",
    "    \"plot_type\": \"all\",  # Type of plot\n",
    "    \"plots\": False,  # Flag to indicate if plots should be generated\n",
    "    \"elev_rescaling\": True,  # Flag to indicate if elevation rescaling should be done\n",
    "    \"ele_dat\": 3172,  # Elevation of the data\n",
    "    \"ele_cat\": 3295,  # Elevation of the catchment\n",
    "    \"area_glac\": 32.51,  # Area of the glacier\n",
    "    \"ele_glac\": 4068,  # Elevation of the glacier\n",
    "    \"pfilter\": 0  # Filter parameter\n",
    "}\n",
    "param_dict = {\n",
    "    'lr_temp': -0.006077369,  # Lapse rate for temperature\n",
    "    'lr_prec': 0.0013269137,  # Lapse rate for precipitation\n",
    "    'BETA': 5.654754,\n",
    "    'CET': 0.08080378,\n",
    "    'FC': 365.68375,  # Field capacity\n",
    "    'K0': 0.36890236,  # K0 parameter\n",
    "    'K1': 0.022955153,  # K1 parameter\n",
    "    'K2': 0.060069658,  # K2 parameter\n",
    "    'LP': 0.63395154,  # LP parameter\n",
    "    'MAXBAS': 5.094901,  # Maximum basin storage\n",
    "    'PERC': 0.39491335,  # Percolation\n",
    "    'UZL': 348.0978,  # Upper zone limit\n",
    "    'PCORR': 1.0702422,  # Precipitation correction\n",
    "    'TT_snow': -1.1521467,  # Temperature threshold for snow\n",
    "    'TT_diff': 1.5895765,  # Temperature difference\n",
    "    'CFMAX_ice': 3.6518102,  # Maximum ice content\n",
    "    'CFMAX_rel': 1.8089349,  # Maximum relative content\n",
    "    'SFCF': 0.42293832,  # Soil field capacity\n",
    "    'CWH': 0.11234668,  # Crop water holding capacity\n",
    "    'AG': 0.9618855,\n",
    "    'RFS': 0.11432563  # Rainfall sensitivity ???\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b272ac4-724c-401b-8ace-86a31b94aae2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## Read adjusted CMIP6 data\n",
    "\n",
    "tas = pickle_to_dict(test_dir + 'adjusted/tas.pickle')\n",
    "pr = pickle_to_dict(test_dir + 'adjusted/pr.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6967a309-7dec-4b81-971c-aacb0d541e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create MATILDA input\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_scenario_dict(tas: dict, pr: dict, scenario_nums: list) -> dict:\n",
    "    \"\"\"\n",
    "    Create a nested dictionary of scenarios and models from two dictionaries of pandas DataFrames.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tas : dict\n",
    "        A dictionary of pandas DataFrames where the keys are scenario names and each DataFrame has columns\n",
    "        representing different climate model mean daily temperature (K) time series.\n",
    "    pr : dict\n",
    "        A dictionary of pandas DataFrames where the keys are scenario names and each DataFrame has columns\n",
    "        representing different climate models mean daily precipitation (mm/day) time series.\n",
    "    scenario_nums : list\n",
    "        A list of integers representing the scenario numbers to include in the resulting dictionary.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A nested dictionary where the top-level keys are scenario names (e.g. 'SSP2', 'SSP5') and the values are\n",
    "        dictionaries containing climate models as keys and the corresponding pandas DataFrames as values.\n",
    "        The DataFrames have three columns: 'TIMESTAMP', 'T2', and 'RRR', where 'TIMESTAMP'\n",
    "        represents the time step, 'T2' represents the mean daily temperature (K), and 'RRR' represents the mean\n",
    "        daily precipitation (mm/day).\n",
    "    \"\"\"\n",
    "    scenarios = {}\n",
    "    for s in scenario_nums:\n",
    "        s = 'SSP' + str(s)\n",
    "        scenarios[s] = {}\n",
    "        for m in tas[s].columns:\n",
    "            model = pd.DataFrame({'T2': tas[s][m],\n",
    "                                  'RRR': pr[s][m]})\n",
    "            model = model.reset_index()\n",
    "            mod_dict = {m: model.rename(columns={'time': 'TIMESTAMP'})}\n",
    "            scenarios[s].update(mod_dict)\n",
    "    return scenarios\n",
    "\n",
    "scenarios = create_scenario_dict(tas, pr, [2, 5])\n",
    "dict_to_pickle(scenarios, test_dir + 'adjusted/matilda_input.pickle')\n",
    "\n",
    "# scenarios = pickle_to_dict(test_dir + 'adjusted/matilda_input.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f082b4d-db3d-437f-9be7-b141d13d4aba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scenarios SSP2 and SSP5: 100%|███████████████████| 2/2 [04:33<00:00, 136.91s/it]\n"
     ]
    }
   ],
   "source": [
    "## Run Matilda in a loop (takes a while - have a coffee)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import contextlib\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class MatildaBulkProcessor:\n",
    "    \"\"\"\n",
    "    A class to run multiple MATILDA simulations for different input scenarios and models in single or multi-processing\n",
    "    mode and store the results in a dictionary.\n",
    "    Attributes\n",
    "    ----------\n",
    "    scenarios : dict\n",
    "        A dictionary with scenario names as keys and a dictionary of climate models as values.\n",
    "    matilda_settings : dict\n",
    "        A dictionary of MATILDA settings.\n",
    "    matilda_parameters : dict\n",
    "        A dictionary of MATILDA parameter values.\n",
    "    Methods\n",
    "    -------\n",
    "    run_single_process():\n",
    "        Runs the MATILDA simulations for the scenarios and models in single-processing mode and returns a dictionary\n",
    "        of results.\n",
    "    run_multi_process():\n",
    "        Runs the MATILDA simulations for the scenarios and models in multi-processing mode and returns a dictionary\n",
    "        of results.\n",
    "    matilda_headless(df, matilda_settings, matilda_parameters):\n",
    "        A helper function to run a single MATILDA simulation given a dataframe, MATILDA settings and parameter\n",
    "        values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scenarios, matilda_settings, matilda_parameters):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        scenarios : dict\n",
    "            A dictionary with scenario names as keys and a dictionary of models as values.\n",
    "        matilda_settings : dict\n",
    "            A dictionary of MATILDA settings.\n",
    "        matilda_parameters : dict\n",
    "            A dictionary of MATILDA parameter values.\n",
    "        \"\"\"\n",
    "\n",
    "        self.scenarios = scenarios\n",
    "        self.matilda_settings = matilda_settings\n",
    "        self.matilda_parameters = matilda_parameters\n",
    "\n",
    "    @staticmethod\n",
    "    def matilda_headless(df, matilda_settings, matilda_parameters):\n",
    "        \"\"\"\n",
    "        A helper function to run a single MATILDA simulation given a dataframe, MATILDA settings and parameter\n",
    "        values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            The input dataframe for the MATILDA simulation.\n",
    "        matilda_settings : dict\n",
    "            A dictionary of MATILDA settings.\n",
    "        matilda_parameters : dict\n",
    "            A dictionary of MATILDA parameter values.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing the MATILDA model output and glacier rescaling factor.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(os.devnull, 'w') as devnull:\n",
    "            with contextlib.redirect_stdout(devnull):\n",
    "                output = matilda_simulation(df, **matilda_settings, parameter_set=matilda_parameters)\n",
    "        return {'model_output': output[0], 'glacier_rescaling': output[5]}\n",
    "\n",
    "    def run_single_process(self):\n",
    "        \"\"\"\n",
    "        Runs the MATILDA simulations for the scenarios and models in single-processing mode and returns a dictionary\n",
    "        of results.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of MATILDA simulation results.\n",
    "        \"\"\"\n",
    "\n",
    "        out_dict = {}  # Create an empty dictionary to store the outputs\n",
    "        # Loop over the scenarios with progress bar\n",
    "        for scenario in self.scenarios.keys():\n",
    "            model_dict = {}  # Create an empty dictionary to store the model outputs\n",
    "            # Loop over the models with progress bar\n",
    "            for model in tqdm(self.scenarios[scenario].keys(), desc=scenario):\n",
    "                # Get the dataframe for the current scenario and model\n",
    "                df = self.scenarios[scenario][model]\n",
    "                # Run the model simulation and get the output while suppressing prints\n",
    "                model_output = self.matilda_headless(df, self.matilda_settings, self.matilda_parameters)\n",
    "                # Store the list of output in the model dictionary\n",
    "                model_dict[model] = model_output\n",
    "            # Store the model dictionary in the scenario dictionary\n",
    "            out_dict[scenario] = model_dict\n",
    "        return out_dict\n",
    "\n",
    "    def run_multi_process(self):\n",
    "        \"\"\"\n",
    "        Runs the MATILDA simulations for the scenarios and models in multi-processing mode and returns a dictionary\n",
    "        of results.\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of MATILDA simulation results.\n",
    "        \"\"\"\n",
    "\n",
    "        out_dict = {}  # Create an empty dictionary to store the outputs\n",
    "        with Pool() as pool:\n",
    "            # Loop over the scenarios with progress bar\n",
    "            for scenario in tqdm(self.scenarios.keys(), desc=\"Scenarios SSP2 and SSP5\"):\n",
    "                model_dict = {}  # Create an empty dictionary to store the model outputs\n",
    "                # Loop over the models with progress bar\n",
    "                model_list = [self.scenarios[scenario][m] for m in self.scenarios[scenario].keys()]\n",
    "                for model, model_output in zip(self.scenarios[scenario], pool.map(\n",
    "                        partial(self.matilda_headless, matilda_settings=self.matilda_settings,\n",
    "                                matilda_parameters=self.matilda_parameters), model_list)):\n",
    "                    model_dict[model] = model_output\n",
    "                # Store the model dictionary in the scenario dictionary\n",
    "                out_dict[scenario] = model_dict\n",
    "            pool.close()\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "\n",
    "matilda_bulk = MatildaBulkProcessor(scenarios, matilda_settings, param_dict)\n",
    "# matilda_scenarios = matilda_bulk.run_single_process()\n",
    "matilda_scenarios = matilda_bulk.run_multi_process()\n",
    "\n",
    "dict_to_pickle(matilda_scenarios, test_dir + 'adjusted/matilda_scenarios.pickle')\n",
    "\n",
    "# matilda_scenarios = pickle_to_dict(test_dir + 'adjusted/matilda_scenarios.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d42cd0-2306-449a-9b43-4c6efd0cc917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing parquet files: 100%|██████████████████████| 2/2 [00:20<00:00, 10.37s/it]\n",
      "Reading parquet files: 100%|██████████████████████| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "## Store results in parquet files to limit storage costs\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from fastparquet import write\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def dict_to_parquet(dictionary: dict, directory_path: str, pbar: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Recursively stores the dataframes in the input dictionary as parquet files in the specified directory.\n",
    "    Nested dictionaries are supported. If the specified directory does not exist, it will be created.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary : dict\n",
    "        A nested dictionary containing pandas dataframes.\n",
    "    directory_path : str\n",
    "        The directory path to store the parquet files.\n",
    "    pbar : bool, optional\n",
    "        A flag indicating whether to display a progress bar. Default is True.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "    if pbar:\n",
    "        bar_iter = tqdm(dictionary.items(), desc='Writing parquet files: ')\n",
    "    else:\n",
    "        bar_iter = dictionary.items()\n",
    "    for k, v in bar_iter:\n",
    "        if isinstance(v, dict):\n",
    "            dict_to_parquet(v, os.path.join(directory_path, k), pbar=False)\n",
    "        else:\n",
    "            file_path = os.path.join(directory_path, k + \".parquet\")\n",
    "            write(file_path, v, compression='GZIP')\n",
    "\n",
    "\n",
    "def parquet_to_dict(directory_path: str, pbar: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Recursively loads the dataframes from the parquet files in the specified directory and returns a dictionary.\n",
    "    Nested directories are supported.\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_path : str\n",
    "        The directory path containing the parquet files.\n",
    "    pbar : bool, optional\n",
    "        A flag indicating whether to display a progress bar. Default is True.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the loaded pandas dataframes.\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    if pbar:\n",
    "        bar_iter = tqdm(sorted(os.listdir(directory_path)), desc='Reading parquet files: ')\n",
    "    else:\n",
    "        bar_iter = sorted(os.listdir(directory_path))\n",
    "    for file_name in bar_iter:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isdir(file_path):\n",
    "            dictionary[file_name] = parquet_to_dict(file_path, pbar=False)\n",
    "        elif file_name.endswith(\".parquet\"):\n",
    "            k = file_name[:-len(\".parquet\")]\n",
    "            dictionary[k] = pd.read_parquet(file_path)\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "# Store dictionary in Parquet files\n",
    "dict_to_parquet(matilda_scenarios, test_dir + 'adjusted/parquet')\n",
    "# Load dictionary from Parquet files\n",
    "matilda_scenarios = parquet_to_dict(test_dir + 'adjusted/parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcda2bc-d73d-4a16-b162-64480188eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCESS-CM2</th>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <th>CESM2</th>\n",
       "      <th>CESM2-WACCM</th>\n",
       "      <th>CMCC-CM2-SR5</th>\n",
       "      <th>CMCC-ESM2</th>\n",
       "      <th>CNRM-CM6-1</th>\n",
       "      <th>CNRM-ESM2-1</th>\n",
       "      <th>CanESM5</th>\n",
       "      <th>...</th>\n",
       "      <th>KACE-1-0-G</th>\n",
       "      <th>KIOST-ESM</th>\n",
       "      <th>MIROC-ES2L</th>\n",
       "      <th>MIROC6</th>\n",
       "      <th>MPI-ESM1-2-HR</th>\n",
       "      <th>MPI-ESM1-2-LR</th>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <th>NESM3</th>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <th>UKESM1-0-LL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-12-31</th>\n",
       "      <td>489.219627</td>\n",
       "      <td>595.058029</td>\n",
       "      <td>346.821137</td>\n",
       "      <td>629.315532</td>\n",
       "      <td>578.142931</td>\n",
       "      <td>563.517190</td>\n",
       "      <td>746.864899</td>\n",
       "      <td>578.373783</td>\n",
       "      <td>703.129751</td>\n",
       "      <td>536.197463</td>\n",
       "      <td>...</td>\n",
       "      <td>398.984865</td>\n",
       "      <td>701.444736</td>\n",
       "      <td>446.305468</td>\n",
       "      <td>143.678270</td>\n",
       "      <td>476.890545</td>\n",
       "      <td>137.049389</td>\n",
       "      <td>554.900912</td>\n",
       "      <td>290.756861</td>\n",
       "      <td>576.131687</td>\n",
       "      <td>681.752345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-12-31</th>\n",
       "      <td>652.972977</td>\n",
       "      <td>681.485047</td>\n",
       "      <td>453.904854</td>\n",
       "      <td>653.164449</td>\n",
       "      <td>695.314827</td>\n",
       "      <td>615.249419</td>\n",
       "      <td>628.733465</td>\n",
       "      <td>477.512990</td>\n",
       "      <td>665.219233</td>\n",
       "      <td>698.445654</td>\n",
       "      <td>...</td>\n",
       "      <td>476.225167</td>\n",
       "      <td>464.201889</td>\n",
       "      <td>573.875621</td>\n",
       "      <td>385.559960</td>\n",
       "      <td>528.778428</td>\n",
       "      <td>519.109059</td>\n",
       "      <td>521.157326</td>\n",
       "      <td>489.860012</td>\n",
       "      <td>602.291544</td>\n",
       "      <td>748.047617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-12-31</th>\n",
       "      <td>619.680708</td>\n",
       "      <td>590.854720</td>\n",
       "      <td>477.595450</td>\n",
       "      <td>691.240057</td>\n",
       "      <td>755.362363</td>\n",
       "      <td>608.752965</td>\n",
       "      <td>642.878796</td>\n",
       "      <td>553.391766</td>\n",
       "      <td>661.916801</td>\n",
       "      <td>438.211426</td>\n",
       "      <td>...</td>\n",
       "      <td>532.132902</td>\n",
       "      <td>333.981245</td>\n",
       "      <td>484.701611</td>\n",
       "      <td>558.510751</td>\n",
       "      <td>812.636811</td>\n",
       "      <td>663.039360</td>\n",
       "      <td>370.546618</td>\n",
       "      <td>503.755533</td>\n",
       "      <td>764.764122</td>\n",
       "      <td>787.952487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31</th>\n",
       "      <td>794.595243</td>\n",
       "      <td>523.181282</td>\n",
       "      <td>604.361125</td>\n",
       "      <td>580.936525</td>\n",
       "      <td>758.916001</td>\n",
       "      <td>527.498612</td>\n",
       "      <td>607.489740</td>\n",
       "      <td>449.989307</td>\n",
       "      <td>500.299186</td>\n",
       "      <td>677.531880</td>\n",
       "      <td>...</td>\n",
       "      <td>719.125083</td>\n",
       "      <td>482.652626</td>\n",
       "      <td>289.495486</td>\n",
       "      <td>672.657340</td>\n",
       "      <td>631.766449</td>\n",
       "      <td>303.580676</td>\n",
       "      <td>477.272085</td>\n",
       "      <td>440.321661</td>\n",
       "      <td>683.011302</td>\n",
       "      <td>652.502181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096-12-31</th>\n",
       "      <td>-1288.241220</td>\n",
       "      <td>-1480.041790</td>\n",
       "      <td>-1016.812152</td>\n",
       "      <td>-2061.202811</td>\n",
       "      <td>-1968.941241</td>\n",
       "      <td>-2191.861098</td>\n",
       "      <td>-2449.393345</td>\n",
       "      <td>-2299.754660</td>\n",
       "      <td>-2012.954531</td>\n",
       "      <td>-4251.593032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1090.486306</td>\n",
       "      <td>-1371.340935</td>\n",
       "      <td>-897.186068</td>\n",
       "      <td>-1881.141381</td>\n",
       "      <td>-1832.277070</td>\n",
       "      <td>-1291.982653</td>\n",
       "      <td>-1453.510423</td>\n",
       "      <td>-2162.443748</td>\n",
       "      <td>-1564.078466</td>\n",
       "      <td>-2387.043753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097-12-31</th>\n",
       "      <td>-2571.083660</td>\n",
       "      <td>-1480.781704</td>\n",
       "      <td>-1139.836004</td>\n",
       "      <td>-2078.627509</td>\n",
       "      <td>-1801.911132</td>\n",
       "      <td>-2627.467176</td>\n",
       "      <td>-2239.858493</td>\n",
       "      <td>-2152.262625</td>\n",
       "      <td>-1825.224447</td>\n",
       "      <td>-3623.903549</td>\n",
       "      <td>...</td>\n",
       "      <td>-2045.047084</td>\n",
       "      <td>-2526.697419</td>\n",
       "      <td>-974.421717</td>\n",
       "      <td>-1679.069329</td>\n",
       "      <td>-859.242379</td>\n",
       "      <td>-1769.975810</td>\n",
       "      <td>-1385.699596</td>\n",
       "      <td>-2360.782662</td>\n",
       "      <td>-1453.575313</td>\n",
       "      <td>-2293.768224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098-12-31</th>\n",
       "      <td>-1941.220928</td>\n",
       "      <td>-1792.655160</td>\n",
       "      <td>-1906.818454</td>\n",
       "      <td>-2251.967257</td>\n",
       "      <td>-1743.845374</td>\n",
       "      <td>-1461.817427</td>\n",
       "      <td>-2157.611726</td>\n",
       "      <td>-2439.343272</td>\n",
       "      <td>-2084.710186</td>\n",
       "      <td>-3216.436004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1483.458857</td>\n",
       "      <td>-1368.052391</td>\n",
       "      <td>-2067.970254</td>\n",
       "      <td>-1972.841972</td>\n",
       "      <td>-1281.312149</td>\n",
       "      <td>-1318.289899</td>\n",
       "      <td>-1558.632339</td>\n",
       "      <td>-1075.030866</td>\n",
       "      <td>-1566.479434</td>\n",
       "      <td>-2506.163565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099-12-31</th>\n",
       "      <td>-2436.369518</td>\n",
       "      <td>-1982.526982</td>\n",
       "      <td>-1075.516051</td>\n",
       "      <td>-1692.580493</td>\n",
       "      <td>-2312.576369</td>\n",
       "      <td>-1563.180834</td>\n",
       "      <td>-2376.998974</td>\n",
       "      <td>-2028.512625</td>\n",
       "      <td>-2289.604763</td>\n",
       "      <td>-3963.892992</td>\n",
       "      <td>...</td>\n",
       "      <td>-1331.042008</td>\n",
       "      <td>-1888.471132</td>\n",
       "      <td>-2300.166545</td>\n",
       "      <td>-1741.934115</td>\n",
       "      <td>-1139.945274</td>\n",
       "      <td>-1228.108574</td>\n",
       "      <td>-1027.212287</td>\n",
       "      <td>-1855.479335</td>\n",
       "      <td>-1773.241578</td>\n",
       "      <td>-2713.824498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100-12-31</th>\n",
       "      <td>-2416.179970</td>\n",
       "      <td>-1732.514015</td>\n",
       "      <td>-1892.541574</td>\n",
       "      <td>-1794.611666</td>\n",
       "      <td>-1585.368051</td>\n",
       "      <td>-2175.146251</td>\n",
       "      <td>-2946.806723</td>\n",
       "      <td>-2664.010744</td>\n",
       "      <td>-1580.986566</td>\n",
       "      <td>-4077.191461</td>\n",
       "      <td>...</td>\n",
       "      <td>-1800.969124</td>\n",
       "      <td>-1716.115835</td>\n",
       "      <td>-964.129898</td>\n",
       "      <td>-1786.428259</td>\n",
       "      <td>-1684.737978</td>\n",
       "      <td>-1745.614368</td>\n",
       "      <td>-1513.818200</td>\n",
       "      <td>-1952.698892</td>\n",
       "      <td>-1915.638167</td>\n",
       "      <td>-2959.967230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACCESS-CM2  ACCESS-ESM1-5  BCC-CSM2-MR        CESM2  CESM2-WACCM  \\\n",
       "TIMESTAMP                                                                       \n",
       "1980-12-31     0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "1981-12-31   489.219627     595.058029   346.821137   629.315532   578.142931   \n",
       "1982-12-31   652.972977     681.485047   453.904854   653.164449   695.314827   \n",
       "1983-12-31   619.680708     590.854720   477.595450   691.240057   755.362363   \n",
       "1984-12-31   794.595243     523.181282   604.361125   580.936525   758.916001   \n",
       "...                 ...            ...          ...          ...          ...   \n",
       "2096-12-31 -1288.241220   -1480.041790 -1016.812152 -2061.202811 -1968.941241   \n",
       "2097-12-31 -2571.083660   -1480.781704 -1139.836004 -2078.627509 -1801.911132   \n",
       "2098-12-31 -1941.220928   -1792.655160 -1906.818454 -2251.967257 -1743.845374   \n",
       "2099-12-31 -2436.369518   -1982.526982 -1075.516051 -1692.580493 -2312.576369   \n",
       "2100-12-31 -2416.179970   -1732.514015 -1892.541574 -1794.611666 -1585.368051   \n",
       "\n",
       "            CMCC-CM2-SR5    CMCC-ESM2   CNRM-CM6-1  CNRM-ESM2-1      CanESM5  \\\n",
       "TIMESTAMP                                                                      \n",
       "1980-12-31      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1981-12-31    563.517190   746.864899   578.373783   703.129751   536.197463   \n",
       "1982-12-31    615.249419   628.733465   477.512990   665.219233   698.445654   \n",
       "1983-12-31    608.752965   642.878796   553.391766   661.916801   438.211426   \n",
       "1984-12-31    527.498612   607.489740   449.989307   500.299186   677.531880   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "2096-12-31  -2191.861098 -2449.393345 -2299.754660 -2012.954531 -4251.593032   \n",
       "2097-12-31  -2627.467176 -2239.858493 -2152.262625 -1825.224447 -3623.903549   \n",
       "2098-12-31  -1461.817427 -2157.611726 -2439.343272 -2084.710186 -3216.436004   \n",
       "2099-12-31  -1563.180834 -2376.998974 -2028.512625 -2289.604763 -3963.892992   \n",
       "2100-12-31  -2175.146251 -2946.806723 -2664.010744 -1580.986566 -4077.191461   \n",
       "\n",
       "            ...   KACE-1-0-G    KIOST-ESM   MIROC-ES2L       MIROC6  \\\n",
       "TIMESTAMP   ...                                                       \n",
       "1980-12-31  ...     0.000000     0.000000     0.000000     0.000000   \n",
       "1981-12-31  ...   398.984865   701.444736   446.305468   143.678270   \n",
       "1982-12-31  ...   476.225167   464.201889   573.875621   385.559960   \n",
       "1983-12-31  ...   532.132902   333.981245   484.701611   558.510751   \n",
       "1984-12-31  ...   719.125083   482.652626   289.495486   672.657340   \n",
       "...         ...          ...          ...          ...          ...   \n",
       "2096-12-31  ... -1090.486306 -1371.340935  -897.186068 -1881.141381   \n",
       "2097-12-31  ... -2045.047084 -2526.697419  -974.421717 -1679.069329   \n",
       "2098-12-31  ... -1483.458857 -1368.052391 -2067.970254 -1972.841972   \n",
       "2099-12-31  ... -1331.042008 -1888.471132 -2300.166545 -1741.934115   \n",
       "2100-12-31  ... -1800.969124 -1716.115835  -964.129898 -1786.428259   \n",
       "\n",
       "            MPI-ESM1-2-HR  MPI-ESM1-2-LR   MRI-ESM2-0        NESM3  \\\n",
       "TIMESTAMP                                                            \n",
       "1980-12-31       0.000000       0.000000     0.000000     0.000000   \n",
       "1981-12-31     476.890545     137.049389   554.900912   290.756861   \n",
       "1982-12-31     528.778428     519.109059   521.157326   489.860012   \n",
       "1983-12-31     812.636811     663.039360   370.546618   503.755533   \n",
       "1984-12-31     631.766449     303.580676   477.272085   440.321661   \n",
       "...                   ...            ...          ...          ...   \n",
       "2096-12-31   -1832.277070   -1291.982653 -1453.510423 -2162.443748   \n",
       "2097-12-31    -859.242379   -1769.975810 -1385.699596 -2360.782662   \n",
       "2098-12-31   -1281.312149   -1318.289899 -1558.632339 -1075.030866   \n",
       "2099-12-31   -1139.945274   -1228.108574 -1027.212287 -1855.479335   \n",
       "2100-12-31   -1684.737978   -1745.614368 -1513.818200 -1952.698892   \n",
       "\n",
       "             NorESM2-MM  UKESM1-0-LL  \n",
       "TIMESTAMP                             \n",
       "1980-12-31     0.000000     0.000000  \n",
       "1981-12-31   576.131687   681.752345  \n",
       "1982-12-31   602.291544   748.047617  \n",
       "1983-12-31   764.764122   787.952487  \n",
       "1984-12-31   683.011302   652.502181  \n",
       "...                 ...          ...  \n",
       "2096-12-31 -1564.078466 -2387.043753  \n",
       "2097-12-31 -1453.575313 -2293.768224  \n",
       "2098-12-31 -1566.479434 -2506.163565  \n",
       "2099-12-31 -1773.241578 -2713.824498  \n",
       "2100-12-31 -1915.638167 -2959.967230  \n",
       "\n",
       "[121 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create custom dataframes for analysis\n",
    "\n",
    "def custom_df(dic, scenario, var, resample_freq=None):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of model outputs and returns a combined dataframe of a specific variable for a given scenario.\n",
    "    Parameters\n",
    "    -------\n",
    "    dic : dict\n",
    "        A nested dictionary of model outputs.\n",
    "        The outer keys are scenario names and the inner keys are model names.\n",
    "        The corresponding values are dictionaries containing two keys:\n",
    "        'model_output' (DataFrame): containing model outputs for a given scenario and model\n",
    "        'glacier_rescaling' (DataFrame): containing glacier properties for a given scenario and model\n",
    "    scenario : str\n",
    "        The name of the scenario to select from the dictionary.\n",
    "    var : str\n",
    "        The name of the variable to extract from the model output DataFrame.\n",
    "    resample_freq : str, optional\n",
    "        The frequency of the resulting time series data.\n",
    "        Defaults to None (i.e. no resampling).\n",
    "        If provided, should be in pandas resample frequency string format.\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the combined data of the specified variable for the selected scenario\n",
    "        and models. The DataFrame is indexed by the time steps of the original models.\n",
    "        The columns are the names of the models in the selected scenario.\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError\n",
    "        If the provided  var  string is not one of the following: ['avg_temp_catchment', 'avg_temp_glaciers',\n",
    "        'evap_off_glaciers', 'prec_off_glaciers', 'prec_on_glaciers', 'rain_off_glaciers', 'snow_off_glaciers',\n",
    "        'rain_on_glaciers', 'snow_on_glaciers', 'snowpack_off_glaciers', 'soil_moisture', 'upper_groundwater',\n",
    "        'lower_groundwater', 'melt_off_glaciers', 'melt_on_glaciers', 'ice_melt_on_glaciers', 'snow_melt_on_glaciers',\n",
    "        'refreezing_ice', 'refreezing_snow', 'total_refreezing', 'SMB', 'actual_evaporation', 'total_precipitation',\n",
    "        'total_melt', 'runoff_without_glaciers', 'runoff_from_glaciers', 'total_runoff', 'glacier_area',\n",
    "        'glacier_elev', 'smb_water_year', 'smb_scaled', 'smb_scaled_capped', 'smb_scaled_capped_cum', 'surplus']\n",
    "    \"\"\"\n",
    "    out1_cols = ['avg_temp_catchment', 'avg_temp_glaciers', 'evap_off_glaciers',\n",
    "                 'prec_off_glaciers', 'prec_on_glaciers', 'rain_off_glaciers',\n",
    "                 'snow_off_glaciers', 'rain_on_glaciers', 'snow_on_glaciers',\n",
    "                 'snowpack_off_glaciers', 'soil_moisture', 'upper_groundwater',\n",
    "                 'lower_groundwater', 'melt_off_glaciers', 'melt_on_glaciers',\n",
    "                 'ice_melt_on_glaciers', 'snow_melt_on_glaciers', 'refreezing_ice',\n",
    "                 'refreezing_snow', 'total_refreezing', 'SMB', 'actual_evaporation',\n",
    "                 'total_precipitation', 'total_melt', 'runoff_without_glaciers',\n",
    "                 'runoff_from_glaciers', 'total_runoff']\n",
    "\n",
    "    out2_cols = ['glacier_area', 'glacier_elev', 'smb_water_year',\n",
    "                 'smb_scaled', 'smb_scaled_capped', 'smb_scaled_capped_cum',\n",
    "                 'surplus']\n",
    "\n",
    "    if var in out1_cols:\n",
    "        output_df = 'model_output'\n",
    "    elif var in out2_cols:\n",
    "        output_df = 'glacier_rescaling'\n",
    "    else:\n",
    "        raise ValueError(\"var needs to be one of the following strings: \" +\n",
    "                         str([out1_cols, out2_cols]))\n",
    "\n",
    "    # Create an empty list to store the dataframes\n",
    "    dfs = []\n",
    "    # Loop over the models in the selected scenario\n",
    "    for model in dic[scenario].keys():\n",
    "        # Get the dataframe for the current model\n",
    "        df = dic[scenario][model][output_df]\n",
    "        # Append the dataframe to the list of dataframes\n",
    "        dfs.append(df[var])\n",
    "    # Concatenate the dataframes into a single dataframe\n",
    "    combined_df = pd.concat(dfs, axis=1)\n",
    "    # Set the column names of the combined dataframe to the model names\n",
    "    combined_df.columns = dic[scenario].keys()\n",
    "    # Resample time series\n",
    "    if resample_freq is not None:\n",
    "        if output_df == 'glacier_rescaling':\n",
    "            if var in ['glacier_area', 'glacier_elev']:\n",
    "                combined_df = combined_df.resample(resample_freq).mean()\n",
    "            else:\n",
    "                combined_df = combined_df.resample(resample_freq).sum()\n",
    "        else:\n",
    "            if var in ['avg_temp_catchment', 'avg_temp_glaciers']:\n",
    "                combined_df = combined_df.resample(resample_freq).mean()\n",
    "            else:\n",
    "                combined_df = combined_df.resample(resample_freq).sum()\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "custom_df(matilda_scenarios, scenario='SSP5', var='smb_water_year', resample_freq='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e41f2a-7bba-4686-b3c7-256b04917cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
