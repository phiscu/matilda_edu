{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3df8e06",
   "metadata": {},
   "source": [
    "# Running MATILDA for the training period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8ab37",
   "metadata": {},
   "source": [
    "- create settings.yaml (here or in the other Notebooks)\n",
    "- run MATILDA with default parameters\n",
    "- (split in calibration and validation samples)\n",
    "- run mspot with few iterations\n",
    "- write best parameter set to yaml\n",
    "- run matilda with best parameter set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d98884",
   "metadata": {},
   "source": [
    "Some helper functions to work with yaml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e086e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def read_yaml(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        return data\n",
    "    \n",
    "def write_yaml(data, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        yaml.safe_dump(data, f)\n",
    "\n",
    "def update_yaml(file_path, new_items):\n",
    "    data = read_yaml(file_path)\n",
    "    data.update(new_items)\n",
    "    write_yaml(data, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9008ff",
   "metadata": {},
   "source": [
    "Read data required for MATILDA from the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import ast\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# get output dir and date range from config.ini\n",
    "dir_output = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "date_range = ast.literal_eval(config['CONFIG']['DATE_RANGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5c45d",
   "metadata": {},
   "source": [
    "Derive setup and modeling periods from the defined time period. Default is to use the first two years as spinup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "length_of_setup_period = 2\n",
    "\n",
    "sim_start = pd.to_datetime(date_range[0]) + pd.DateOffset(years = length_of_setup_period)\n",
    "set_up_end = sim_start - pd.DateOffset(days = 1)\n",
    "\n",
    "dates = {'set_up_start': date_range[0],\n",
    "        'set_up_end': str(set_up_end).split(' ')[0],        # remove hh:mm:ss\n",
    "        'sim_start': str(sim_start).split(' ')[0],          # remove hh:mm:ss\n",
    "        'sim_end': date_range[1]}\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded67ceb",
   "metadata": {},
   "source": [
    "Append the dates to the settings.yml with stored catchment information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2156458",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_yaml(dir_output + 'settings.yml', dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682af77",
   "metadata": {},
   "source": [
    "Check the remaining settings, append them to the settings file and load it as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1f49e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "remaining_settings = {\"freq\": \"M\",            # aggregation level of model outputs (D, M, Y)\n",
    "                      \"warn\": False,          # show warnings of subpackages?\n",
    "                      \"plot_type\": \"all\",     # interactive and/or non-interactive plots ('print', 'interactive', 'all')\n",
    "                      \"elev_rescaling\": True  # \n",
    "                     }\n",
    "\n",
    "update_yaml(dir_output + 'settings.yml', remaining_settings)\n",
    "\n",
    "settings = read_yaml(dir_output + 'settings.yml')\n",
    "glacier_profile = pd.read_csv(dir_output + 'glacier_profile.csv')\n",
    "settings['glacier_profile'] = glacier_profile\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71caaa08",
   "metadata": {},
   "source": [
    "# Run MATILDA with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48354ae",
   "metadata": {},
   "source": [
    "Load forcing and obs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5 = pd.read_csv(dir_output + 'ERA5L.csv', usecols=['temp', 'prec', 'dt'])\n",
    "era5.columns = ['T2', 'RRR', 'TIMESTAMP']\n",
    "\n",
    "obs = pd.read_csv('input/' + 'obs_runoff_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34401e0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matilda.core import matilda_simulation\n",
    "\n",
    "# output_matilda = matilda_simulation(era5, obs, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90a149",
   "metadata": {},
   "source": [
    "This is obviously an incorrect result so the model requires calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651599a",
   "metadata": {},
   "source": [
    "# Run MATILDA with calibrated parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ea964",
   "metadata": {},
   "source": [
    "Pass best parameter set from calibration runs as dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300138b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = param = {'lr_temp': -0.006715786655857773,\n",
    " 'lr_prec': 0.0009426868309736729,\n",
    " 'BETA': 4.755073554352201,\n",
    " 'CET': 0.07412818445635777,\n",
    " 'FC': 424.03083598449393,\n",
    " 'K0': 0.24661844658100276,\n",
    " 'K1': 0.013814926672937655,\n",
    " 'K2': 0.01877384431953609,\n",
    " 'LP': 0.7699373762379815,\n",
    " 'MAXBAS': 2.911911446589711,\n",
    " 'PERC': 1.7425269942489015,\n",
    " 'UZL': 392.21464659707215,\n",
    " 'PCORR': 0.796841923720716,\n",
    " 'TT_snow': -0.46045194130701805,\n",
    " 'TT_diff': 1.7514302424196948,\n",
    " 'CFMAX_ice': 7.7265119371929885,\n",
    " 'CFMAX_rel': 1.6284621286938152,\n",
    " 'SFCF': 0.989796885705358,\n",
    " 'CWH': 0.17529112240136024,\n",
    " 'AG': 0.5942337539192579,\n",
    " 'RFS': 0.14722479457349263}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ab95c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_matilda = matilda_simulation(era5, obs, **settings, parameter_set = param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7b931-4d51-428d-af52-0324f0e4c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_matilda[10].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91a2af-cfc8-490b-96e1-c77df150654c",
   "metadata": {},
   "source": [
    "# Calibrate MATILDA using the mspot() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40563dcd-805a-4b46-b517-bd1e55bb7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matilda.mspot_glacier import psample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2d2f9-5a52-4fd8-9986-011cd382b45f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_temp_lo = -0.007; lr_temp_up = -0.005\n",
    "\n",
    "PCORR_lo_era = 0.29; PCORR_up_era = 1.2\n",
    "\n",
    "lim_dict = {'lr_temp_lo': lr_temp_lo, 'lr_temp_up': lr_temp_up, 'PCORR_lo': PCORR_lo_era, 'PCORR_up': PCORR_up_era}\n",
    "\n",
    "best_summary = psample(df=era5, obs=obs, rep=10, #output=output_path + '/glacier_only',\n",
    "                                    **dates, freq=\"D\",\n",
    "                                     area_cat=295.51935296803777, area_glac=31.81370047643339, lat=42.33,\n",
    "                                     ele_dat=3335.668840874115, ele_cat=3293.491688025922, ele_glac=4001.8798828125,\n",
    "                                     glacier_profile=glacier_profile, elev_rescaling=True,\n",
    "                                     glacier_only=False,\n",
    "                                     obj_dir=\"maximize\",\n",
    "                                    **lim_dict,\n",
    "                                     #target_mb=-156,\n",
    "                                     parallel=False, dbformat=None, algorithm='lhs', #cores=20,\n",
    "                                     dbname='era5_matilda_edu_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b4d19-d0a1-48fa-be73-9f28fd5867e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
