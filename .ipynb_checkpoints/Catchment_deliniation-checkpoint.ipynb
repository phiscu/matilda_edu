{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad5d9f7",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a99cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Earth Engine packages\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# other packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Define a function to plot the digital elevation model\n",
    "def plotFigure(data, label, cmap='Blues'):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(data, extent=grid.extent)\n",
    "    plt.colorbar(label=label)\n",
    "    plt.grid()\n",
    "    \n",
    "\n",
    "# constants\n",
    "ee_img = 'Image'\n",
    "ee_ico = 'ImageCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49688cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize GEE at the beginning of session\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()         # authenticate when using GEE for the first time\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c84188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import ast\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# get file config from config.ini\n",
    "output_folder = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "filename = output_folder + config['FILE_SETTINGS']['DEM_FILENAME']\n",
    "output_gpkg = output_folder + config['FILE_SETTINGS']['GPKG_NAME']\n",
    "\n",
    "# get used GEE DEM, coords and other settings\n",
    "dem = ast.literal_eval(config['CONFIG']['DEM'])\n",
    "y, x = ast.literal_eval(config['CONFIG']['COORDS'])\n",
    "show_map = config.getboolean('CONFIG','SHOW_MAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e5e86",
   "metadata": {},
   "source": [
    "# Start GEE and find catchment area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d556010",
   "metadata": {},
   "source": [
    "Start with base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_map:\n",
    "    Map = geemap.Map()\n",
    "    display(Map)\n",
    "else:\n",
    "    print(\"Map view disabled in config.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb5d42",
   "metadata": {},
   "source": [
    "Load selected DEM from GEE catalog and add as layer to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dem[0] == ee_img:\n",
    "    image = ee.Image(dem[1])\n",
    "elif dem[0] == ee_ico:\n",
    "    image = ee.ImageCollection(dem[1]).select(dem[2]).mosaic()\n",
    "\n",
    "if show_map:\n",
    "    srtm_vis = { 'bands': dem[2],\n",
    "                 'min': 0,\n",
    "                 'max': 6000,\n",
    "                'palette': ['000000', '478FCD', '86C58E', 'AFC35E', '8F7131','B78D4F', 'E2B8A6', 'FFFFFF']\n",
    "               }\n",
    "\n",
    "    Map.addLayer(image, srtm_vis, dem[3], True, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c13ec",
   "metadata": {},
   "source": [
    "Add configured discharge point to map and automatically draw box with 30km in all directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6900fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point(x,y)\n",
    "box = point.buffer(30000).bounds()\n",
    "\n",
    "if show_map:\n",
    "    Map.addLayer(point,{'color': 'blue'},'Discharge Point')\n",
    "    Map.addLayer(box,{'color': 'grey'},'Catchment Area', True, 0.7)\n",
    "    Map.centerObject(box, zoom=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4aac49",
   "metadata": {},
   "source": [
    "Discharge point (marker) and box (polygon/rectangle) can be added manually to the map above. If features have been drawn, they will overrule the configured discharge point and automatically created box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_map:\n",
    "    for feature in Map.draw_features:\n",
    "        f_type = feature.getInfo()['geometry']['type']\n",
    "        if f_type == 'Point':\n",
    "            point = feature.geometry()\n",
    "            print(\"Manually set pouring point will be considered\")\n",
    "        elif f_type == 'Polygon':\n",
    "            box = feature.geometry()\n",
    "            print(\"Manually drawn box will be considered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33331e98",
   "metadata": {},
   "source": [
    "Export DEM as .tif file to output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "geemap.ee_export_image(image, filename=filename, scale=30, region=box, file_per_band=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713b1ca",
   "metadata": {},
   "source": [
    "# Catchment deliniation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4fdeb9",
   "metadata": {},
   "source": [
    "Use <code>pysheds</code> module to determine catchment area for discharge point. The result will be a raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ff78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# GIS packages\n",
    "from pysheds.grid import Grid\n",
    "import fiona\n",
    "\n",
    "# load DEM\n",
    "DEM_file = filename\n",
    "grid = Grid.from_raster(DEM_file)\n",
    "dem = grid.read_raster(DEM_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fill depressions in DEM\n",
    "flooded_dem = grid.fill_depressions(dem)\n",
    "# Resolve flats in DEM\n",
    "inflated_dem = grid.resolve_flats(flooded_dem)\n",
    "\n",
    "# Specify directional mapping\n",
    "#N    NE    E    SE    S    SW    W    NW\n",
    "dirmap = (64, 128, 1, 2, 4, 8, 16, 32)\n",
    "# Compute flow directions\n",
    "fdir = grid.flowdir(inflated_dem, dirmap=dirmap)\n",
    "#catch = grid.catchment(x=x, y=y, fdir=fdir, dirmap=dirmap, xytype='coordinate')\n",
    "# Compute accumulation\n",
    "acc = grid.accumulation(fdir)\n",
    "# Snap pour point to high accumulation cell\n",
    "x_snap, y_snap = grid.snap_to_mask(acc > 1000, (x, y))\n",
    "# Delineate the catchment\n",
    "catch = grid.catchment(x=x_snap, y=y_snap, fdir=fdir, xytype='coordinate')\n",
    "# Clip the DEM to the catchment\n",
    "grid.clip_to(catch)\n",
    "clipped_catch = grid.view(catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demView = grid.view(dem, nodata=np.nan)\n",
    "plotFigure(demView,'Elevation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294c54a",
   "metadata": {},
   "source": [
    "Convert catchment raster to polygon and save to output folder as geopackage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a571ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import pyproj\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import transform\n",
    "\n",
    "## Create shapefile and save it\n",
    "shapes = grid.polygonize()\n",
    "\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'LABEL': 'float:16'}\n",
    "}\n",
    "\n",
    "catchment_shape = {}\n",
    "layer_name = 'catchment_orig'\n",
    "with fiona.open(output_gpkg, 'w',\n",
    "                #driver='ESRI Shapefile',#\n",
    "                driver='GPKG',\n",
    "                layer=layer_name,\n",
    "                crs=grid.crs.srs,\n",
    "                schema=schema) as c:\n",
    "    i = 0\n",
    "    for shape, value in shapes:\n",
    "        catchment_shape = shape\n",
    "        rec = {}\n",
    "        rec['geometry'] = shape\n",
    "        rec['properties'] = {'LABEL' : str(value)}\n",
    "        rec['id'] = str(i)\n",
    "        c.write(rec)\n",
    "        i += 1 \n",
    "\n",
    "print(f\"Layer '{layer_name}' added to GeoPackage '{output_gpkg}'\\n\")\n",
    "        \n",
    "catchment_bounds = [int(np.nanmin(demView)),int(np.nanmax(demView))]\n",
    "ele_cat = float(np.nanmean(demView))\n",
    "print(f\"Catchment elevation is between {catchment_bounds[0]} m and {catchment_bounds[1]} m\")\n",
    "print(f\"Mean catchment elevation is {str(ele_cat)} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e9447",
   "metadata": {},
   "source": [
    "Add catchment area to map and calculate area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment = ee.Geometry.Polygon(catchment_shape['coordinates'])\n",
    "if show_map:\n",
    "    Map.addLayer(catchment, {}, 'Catchment')\n",
    "\n",
    "catchment_area = catchment.area().divide(1000*1000).getInfo()\n",
    "print(f\"Catchment area is {catchment_area:.2f} kmÂ²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a3b97",
   "metadata": {},
   "source": [
    "# Determine glaciers in catchment area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0002a5f",
   "metadata": {},
   "source": [
    "Find all glacier that are intersecting catchment area in RGI60 database (for area 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# load catcment and RGI regions as DF\n",
    "catchment = gpd.read_file(output_gpkg, layer='catchment_orig')\n",
    "df_areas = gpd.read_file('https://www.glims.org/RGI/rgi60_files/00_rgi60_regions.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utm\n",
    "from pyproj import CRS\n",
    "\n",
    "# get UTM zone for catchment\n",
    "centroid = catchment.centroid\n",
    "utm = utm.from_latlon(centroid.y[0],centroid.x[0])\n",
    "print(f\"UTM zone '{utm[2]}', band '{utm[3]}'\")\n",
    "\n",
    "# get CRS based on UTM\n",
    "crs = CRS.from_dict({'proj':'utm', 'zone':utm[2], 'south':False})\n",
    "\n",
    "catchment_area = catchment.to_crs(crs).area[0] / 1000 / 1000\n",
    "print(f\"Catchment area (projected) is {catchment_area:.2f} kmÂ²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b998cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas = df_areas.set_crs('EPSG:4326',allow_override=True)\n",
    "catchment = catchment.to_crs('EPSG:4326')\n",
    "df_areas_catchment = gpd.sjoin(df_areas, catchment, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "if len(df_areas_catchment.index) == 0:\n",
    "    print('No area found for catchment')\n",
    "    area = None\n",
    "elif len(df_areas_catchment.index) == 1:\n",
    "    area = df_areas_catchment.iloc[0]['RGI_CODE']\n",
    "    print(f\"Catchment belongs to area {area} ({df_areas_catchment.iloc[0]['FULL_NAME']})\")\n",
    "else:\n",
    "    display(df_areas_catchment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2aa66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "if area != None:\n",
    "    url = \"https://www.glims.org/RGI/rgi60_files/\"  # Replace with the URL of your web server\n",
    "    html_page = urllib.request.urlopen(url)\n",
    "    html_content = html_page.read().decode(\"utf-8\")\n",
    "\n",
    "    # Use regular expressions to find links to files\n",
    "    pattern = re.compile(r'href=\"([^\"]+\\.zip)\"')\n",
    "    file_links = pattern.findall(html_content)\n",
    "\n",
    "\n",
    "    for file in file_links:\n",
    "        splits = file.split(\"_\")\n",
    "        if splits[0] != str(area): \n",
    "            continue\n",
    "\n",
    "        # starting scanning areas\n",
    "        areaname = splits[0] + \" (\" + splits[2].split(\".\")[0] + \")\"\n",
    "        print(f'scanning area {areaname}')\n",
    "\n",
    "        # read zip into dataframe\n",
    "        rgi = gpd.read_file(url+file)\n",
    "        if rgi.crs != catchment.crs:\n",
    "            print(\"CRS adjusted\")\n",
    "            catchment = catchment.to_crs(rgi.crs)\n",
    "\n",
    "        # check whether catchment intersects with glaciers of area\n",
    "        rgi_catchment = gpd.sjoin(rgi,catchment,how='inner',predicate='intersects')\n",
    "        if len(rgi_catchment.index) > 0:\n",
    "            print(f'{len(rgi_catchment.index)} outlines found in area {areaname}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963cb30f",
   "metadata": {},
   "source": [
    "Some glaciers do not belong to catchment but are intersecting the derived catchment area. Therefore, the percentage of the glacier will be calculated to determine whether glacier will be part of catchment or not (>=50% of its area needs to be in catchment). Glaciers outside catchment with overlapping area will reduce catchment area.\n",
    "Results for each glacier can be printed if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa61f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersects selects too many. calculate percentage of glacier area that is within catchment\n",
    "rgi_catchment['rgi_area'] = rgi_catchment.to_crs(crs).area    \n",
    "    \n",
    "gdf_joined = gpd.overlay(catchment,rgi_catchment, how='union')\n",
    "gdf_joined['area_joined'] = gdf_joined.to_crs(crs).area\n",
    "gdf_joined['share_of_area'] = (gdf_joined['area_joined'] / gdf_joined['rgi_area'] * 100)\n",
    "\n",
    "results = (gdf_joined\n",
    "           .groupby(['RGIId','LABEL_1'])\n",
    "           .agg({'share_of_area':'sum'}))\n",
    "\n",
    "#print(results.sort_values(['share_of_area'],ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_catchment = pd.merge(rgi_catchment, results, on=\"RGIId\")\n",
    "rgi_in_catchment = rgi_catchment.loc[rgi_catchment['share_of_area'] >= 50]\n",
    "rgi_out_catchment = rgi_catchment.loc[rgi_catchment['share_of_area'] < 50]\n",
    "\n",
    "catchment_new = gpd.overlay(catchment, rgi_out_catchment, how='difference')\n",
    "catchment_new = gpd.overlay(catchment_new, rgi_in_catchment, how='union')\n",
    "catchment_new = catchment_new.dissolve()[['LABEL_1','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catchment_new['area'] = catchment_new.to_crs(\"+proj=cea +lat_0=35.68250088833567 +lon_0=139.7671 +units=m\")['geometry'].area\n",
    "#area_glac = rgi_in_catchment.to_crs(\"+proj=cea +lat_0=35.68250088833567 +lon_0=139.7671 +units=m\")['geometry'].area\n",
    "catchment_new['area'] = catchment_new.to_crs(crs)['geometry'].area\n",
    "area_glac = rgi_in_catchment.to_crs(crs)['geometry'].area\n",
    "\n",
    "area_glac = area_glac.sum()/1000000\n",
    "area_cat = catchment_new.iloc[0]['area']/1000000\n",
    "lat = catchment_new.centroid.to_crs('EPSG:4326').y[0]\n",
    "print(f\"New catchment area is {area_cat} kmÂ²\")\n",
    "print(f\"Glacierized catchment area is {area_glac} kmÂ²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c36137",
   "metadata": {},
   "source": [
    "Export data to existing geopackage:\n",
    "<ul>\n",
    "    <li>RGI glaciers within catchment</li>\n",
    "    <li>RGI glaciers outside catchment</li>\n",
    "    <li>Adjusted catchment area based in RGI glaciers</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c28a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_in_catchment.to_file(output_gpkg, layer='rgi_in', driver='GPKG')\n",
    "print(f\"Layer 'rgi_in' added to GeoPackage '{output_gpkg}'\")\n",
    "\n",
    "rgi_out_catchment.to_file(output_gpkg, layer='rgi_out', driver='GPKG')\n",
    "print(f\"Layer 'rgi_out' added to GeoPackage '{output_gpkg}'\")\n",
    "\n",
    "catchment_new.to_file(output_gpkg, layer='catchment_new', driver='GPKG')\n",
    "print(f\"Layer 'catchment_new' added to GeoPackage '{output_gpkg}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f710c3",
   "metadata": {},
   "source": [
    "Add determined glaciers and new catchment area to map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220513bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_new = geemap.geopandas_to_ee(catchment_new)\n",
    "rgi = geemap.geopandas_to_ee(rgi_in_catchment)\n",
    "\n",
    "if show_map:\n",
    "    Map.addLayer(c_new, {'color': 'orange'}, \"Catchment New\")\n",
    "    Map.addLayer(rgi, {'color': 'white'}, \"RGI60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39088d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_cat = image.reduceRegion(ee.Reducer.mean(),\n",
    "                          geometry=c_new).getInfo()['dem'] #['elevation']\n",
    "print(f\"Mean catchment elevation (adjusted) is {str(ele_cat)} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ee8f7",
   "metadata": {},
   "source": [
    "The thickness of each glacier must be determined from raster files. Depending on the RGI IDs that are within catchment area, the corresponding raster files will be downloaded from server and stored in output folder.\n",
    "The thinkness raster files will be supported by DEM raster files for easier processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a296f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArchiveNames(row):\n",
    "    split = row['RGIId'].split('-')\n",
    "    area = split[1].split('.')[0]\n",
    "    id = int(split[1].split('.')[1]) // 1000 + 1\n",
    "    return f'ice_thickness_RGI60-{area}_{id}', f'dem_surface_DEM_RGI60-{area}_{id}'\n",
    "\n",
    "\n",
    "# determine relevant .zip files for derived RGI IDs \n",
    "df_rgiids = pd.DataFrame(rgi_in_catchment['RGIId'].sort_values())\n",
    "df_rgiids[['thickness', 'dem']] = df_rgiids.apply(getArchiveNames, axis=1, result_type='expand')\n",
    "zips_thickness = df_rgiids['thickness'].drop_duplicates()\n",
    "zips_dem = df_rgiids['dem'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1722715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resourcespace import ResourceSpace\n",
    "\n",
    "# use guest credentials to access media server\n",
    "api_base_url = 'https://rs.cms.hu-berlin.de/matilda/api/?'  \n",
    "private_key = '9a19c0cee1cde5fe9180c31c27a8145bc6f7a110cfaa3806ba262eb63d16f086' \n",
    "user = 'gast' \n",
    "\n",
    "myrepository = ResourceSpace(api_base_url, user, private_key)\n",
    "\n",
    "# get resource IDs for each .zip file\n",
    "refs_thickness = pd.DataFrame(myrepository.get_collection_resources(12))[['ref', 'file_size', 'file_extension', 'field8']]\n",
    "refs_dem = pd.DataFrame(myrepository.get_collection_resources(21))[['ref', 'file_size', 'file_extension', 'field8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb425e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce list of resources two required zip files \n",
    "refs_thickness = pd.merge(zips_thickness, refs_thickness, left_on='thickness', right_on='field8')\n",
    "refs_dem = pd.merge(zips_dem, refs_dem, left_on='dem', right_on='field8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065e647",
   "metadata": {},
   "source": [
    "# Retrieve raster files for thickness and corresponding DEM raster files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6659f",
   "metadata": {},
   "source": [
    "**Ice thickness**: download relevant archives from server and extract `.tif` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "\n",
    "cnt_thickness = 0\n",
    "file_names_thickness = []\n",
    "for idx,row in refs_thickness.iterrows():   \n",
    "    content = myrepository.get_resource_file(row['ref'])    \n",
    "    with ZipFile(io.BytesIO(content), 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        for rgiid in df_rgiids.loc[df_rgiids['thickness']==row['field8']]['RGIId']:\n",
    "            filename = rgiid + '_thickness.tif'\n",
    "            if filename in listOfFileNames:\n",
    "                cnt_thickness += 1\n",
    "                zipObj.extract(filename, output_folder+'RGI')\n",
    "                file_names_thickness.append(filename)\n",
    "            else:\n",
    "                print(f'File not found: {filename}')\n",
    "                \n",
    "print(f'{cnt_thickness} files have been extracted (ice thickness)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023593d6",
   "metadata": {},
   "source": [
    "**DEM**: download relevant archives from server and extract `.tif` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnt_dem = 0\n",
    "file_names_dem = []\n",
    "for idx,row in refs_dem.iterrows():   \n",
    "    content = myrepository.get_resource_file(row['ref'])    \n",
    "    with ZipFile(io.BytesIO(content), 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        for rgiid in df_rgiids.loc[df_rgiids['dem']==row['field8']]['RGIId']:\n",
    "            filename = f\"surface_DEM_{rgiid}.tif\"\n",
    "            if filename in listOfFileNames:\n",
    "                cnt_dem += 1\n",
    "                zipObj.extract(filename, output_folder+'RGI')\n",
    "                file_names_dem.append(filename)\n",
    "            else:\n",
    "                print(f'File not found: {filename}')\n",
    "                \n",
    "print(f'{cnt_dem} files have been extracted (DEM)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb279f3a",
   "metadata": {},
   "source": [
    "# Glacier profile creation\n",
    "Overlay ice thickness and DEM tif for each glacier to create tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "if cnt_thickness != cnt_dem:\n",
    "    print('Number of thickness raster files does not match number of DEM raster files!')\n",
    "else:\n",
    "    for idx,rgiid in enumerate(df_rgiids['RGIId']):\n",
    "        if rgiid in file_names_thickness[idx] and rgiid in file_names_dem[idx]:\n",
    "            file_list = [\n",
    "                output_folder + 'RGI/' + file_names_thickness[idx],\n",
    "                output_folder + 'RGI/' + file_names_dem[idx]\n",
    "            ]\n",
    "            array_list = []\n",
    "\n",
    "            # Read arrays\n",
    "            for file in file_list:\n",
    "                src = gdal.Open(file)\n",
    "                geotransform = src.GetGeoTransform() # Could be done more elegantly outside the for loop\n",
    "                projection = src.GetProjectionRef()\n",
    "                array_list.append(src.ReadAsArray())\n",
    "                pixelSizeX = geotransform[1]\n",
    "                pixelSizeY =-geotransform[5]                \n",
    "                src = None\n",
    "            \n",
    "            df = pd.DataFrame()\n",
    "            df['thickness'] = array_list[0].flatten()\n",
    "            df['altitude'] = array_list[1].flatten()\n",
    "            df_all = pd.concat([df_all, df])\n",
    "        else:\n",
    "            print(f'Raster files do not match for {rgiid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b91bc2",
   "metadata": {},
   "source": [
    "Remove all points with zero ice thickness and aggregate all points to 10m elevation zones.\n",
    "\n",
    "Export result as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_all) > 0:\n",
    "    df_all = df_all.loc[df_all['thickness'] > 0]\n",
    "    df_all.sort_values(by=['altitude'],inplace=True)\n",
    "    \n",
    "    # get min/max altitude considering catchment and all glaciers\n",
    "    alt_min = 10*int(min(catchment_bounds[0],df_all['altitude'].min())/10)\n",
    "    alt_max = max(catchment_bounds[1],df_all['altitude'].max())+10\n",
    "        \n",
    "    # create bins in 10m steps\n",
    "    bins = np.arange(alt_min, df_all['altitude'].max()+10, 10)\n",
    "    \n",
    "    # aggregate per bin and do some math\n",
    "    df_agg = df_all.groupby(pd.cut(df_all['altitude'], bins))['thickness'].agg(count='size', mean='mean').reset_index()\n",
    "    df_agg['Elevation'] = df_agg['altitude'].apply(lambda x: x.left)\n",
    "    df_agg['Area'] = df_agg['count']*pixelSizeX*pixelSizeY / catchment_new.iloc[0]['area']\n",
    "    df_agg['WE'] = df_agg['mean']*0.908*1000\n",
    "    df_agg['EleZone'] = df_agg['Elevation'].apply(lambda x: 100*int(x/100))\n",
    "    \n",
    "    # delete empty elevation bands but keep at least one entry per elevation zone\n",
    "    df_agg=pd.concat([df_agg.loc[df_agg['count']>0],\n",
    "                      df_agg.loc[df_agg['count']==0].drop_duplicates(['EleZone'],keep='first')]\n",
    "                    ).sort_index()\n",
    "    \n",
    "    df_agg.drop(['altitude', 'count', 'mean'], axis=1, inplace=True)\n",
    "    df_agg = df_agg.replace(np.nan, 0)\n",
    "    df_agg.to_csv(output_folder + 'glacier_profile.csv', header=True, index=False)\n",
    "    print('Glacier profile for catchment successfully created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bfc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_glac = round(df_all.altitude.mean(), 2)\n",
    "print(f'Average glacier elevation in the catchment: {ele_glac} m.a.s.l.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07b15b",
   "metadata": {},
   "source": [
    "Create a settings.yaml and store the relevant catchment information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "settings = {'area_cat': float(area_cat),\n",
    "            'ele_cat': float(ele_cat),\n",
    "            'area_glac': float(area_glac),\n",
    "            'ele_glac': float(ele_glac),\n",
    "            'lat': float(lat)\n",
    "           }\n",
    "with open(output_folder + 'settings.yml', 'w') as f:\n",
    "    yaml.safe_dump(settings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1faa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test edit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
