{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad5d9f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a99cb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Google Earth Engine packages\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# other packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Define a function to plot the digital elevation model\n",
    "def plotFigure(data, label, cmap='Blues'):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(data, extent=grid.extent)\n",
    "    plt.colorbar(label=label)\n",
    "    plt.grid()\n",
    "    \n",
    "\n",
    "# constants\n",
    "ee_img = 'Image'\n",
    "ee_ico = 'ImageCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49688cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize GEE at the beginning of session\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()         # authenticate when using GEE for the first time\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c84188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import ast\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# get file config from config.ini\n",
    "output_folder = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "filename = output_folder + config['FILE_SETTINGS']['DEM_FILENAME']\n",
    "output_gpkg = output_folder + config['FILE_SETTINGS']['GPKG_NAME']\n",
    "download_rgi_dem = config.getboolean('FILE_SETTINGS','DOWNLOAD_RGI_DEM')\n",
    "\n",
    "# get used GEE DEM and coords\n",
    "dem = ast.literal_eval(config['CONFIG']['DEM'])\n",
    "y, x = ast.literal_eval(config['CONFIG']['COORDS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e5e86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Start GEE and find catchment area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d556010",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start with base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7e2b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb5d42",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load selected DEM from GEE catalog and add as layer to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4b21f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if dem[0] == ee_img:\n",
    "    image = ee.Image(dem[1])\n",
    "elif dem[0] == ee_ico:\n",
    "    image = ee.ImageCollection(dem[1]).select(dem[2]).mosaic()\n",
    "    \n",
    "srtm_vis = { 'bands': dem[2],\n",
    "             'min': 0,\n",
    "             'max': 6000,\n",
    "            'palette': ['000000', '478FCD', '86C58E', 'AFC35E', '8F7131','B78D4F', 'E2B8A6', 'FFFFFF']\n",
    "           }\n",
    "Map.addLayer(image, srtm_vis, dem[3], True, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c13ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add configured discharge point to map and automatically draw box with 30km in all directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6900fdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point(x,y)\n",
    "Map.addLayer(point,{'color': 'blue'},'Discharge Point');\n",
    "\n",
    "box = point.buffer(30000).bounds()\n",
    "Map.addLayer(box,{'color': 'grey'},'Catchment Area', True, 0.7);\n",
    "Map.centerObject(box, zoom=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4aac49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Discharge point (marker) and box (polygon/rectangle) can be added manually to the map above. If features have been drawn, they will overrule the configured discharge point and automatically created box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd6a64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in Map.draw_features:\n",
    "    f_type = feature.getInfo()['geometry']['type']\n",
    "    if f_type == 'Point':\n",
    "        point = feature.geometry()\n",
    "        print(\"Manually set pouring point will be considered\")\n",
    "    elif f_type == 'Polygon':\n",
    "        box = feature.geometry()\n",
    "        print(\"Manually drawn box will be considered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33331e98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Export DEM as .tif file to output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05aad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "geemap.ee_export_image(image, filename=filename, scale=30, region=box, file_per_band=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713b1ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Catchment deliniation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4fdeb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use <code>pysheds</code> module to determine catchment area for discharge point. The result will be a raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ff78a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GIS packages\n",
    "from pysheds.grid import Grid\n",
    "import fiona\n",
    "\n",
    "DEM_file = filename\n",
    "# Plot the DEM\n",
    "grid = Grid.from_raster(DEM_file)\n",
    "dem = grid.read_raster(DEM_file)\n",
    "grid.view(dem)\n",
    "# Fill depressions in DEM\n",
    "flooded_dem = grid.fill_depressions(dem)\n",
    "# Resolve flats in DEM\n",
    "inflated_dem = grid.resolve_flats(flooded_dem)\n",
    "# Specify directional mapping\n",
    "#N    NE    E    SE    S    SW    W    NW\n",
    "dirmap = (64, 128, 1, 2, 4, 8, 16, 32)\n",
    "# Compute flow directions\n",
    "fdir = grid.flowdir(inflated_dem, dirmap=dirmap)\n",
    "#catch = grid.catchment(x=x, y=y, fdir=fdir, dirmap=dirmap, xytype='coordinate')\n",
    "# Compute accumulation\n",
    "acc = grid.accumulation(fdir)\n",
    "# Snap pour point to high accumulation cell\n",
    "x_snap, y_snap = grid.snap_to_mask(acc > 1000, (x, y))\n",
    "# Delineate the catchment\n",
    "catch = grid.catchment(x=x_snap, y=y_snap, fdir=fdir, xytype='coordinate')\n",
    "# Clip the DEM to the catchment\n",
    "grid.clip_to(catch)\n",
    "clipped_catch = grid.view(catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b11fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demView = grid.view(dem, nodata=np.nan)\n",
    "plotFigure(demView,'Elevation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294c54a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert catchment raster to polygon and save to output folder as geopackage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a571ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import pyproj\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import transform\n",
    "\n",
    "## Create shapefile and save it\n",
    "shapes = grid.polygonize()\n",
    "\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'LABEL': 'float:16'}\n",
    "}\n",
    "\n",
    "catchment_shape = {}\n",
    "with fiona.open(output_gpkg, 'w',\n",
    "                #driver='ESRI Shapefile',#\n",
    "                driver='GPKG',\n",
    "                layer='catchment_orig',\n",
    "                crs=grid.crs.srs,\n",
    "                schema=schema) as c:\n",
    "    i = 0\n",
    "    for shape, value in shapes:\n",
    "        catchment_shape = shape\n",
    "        rec = {}\n",
    "        rec['geometry'] = shape\n",
    "        rec['properties'] = {'LABEL' : str(value)}\n",
    "        rec['id'] = str(i)\n",
    "        c.write(rec)\n",
    "        i += 1      \n",
    "\n",
    "catchment_bounds = [int(np.nanmin(demView)),int(np.nanmax(demView))]\n",
    "ele_cat = float(np.nanmean(demView))\n",
    "print(f\"Catchment elevation is between {catchment_bounds[0]} m and {catchment_bounds[1]} m\")\n",
    "print(f\"Mean catchment elevation is {str(ele_cat)} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e9447",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add catchment area to map and calculate area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc5d84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "catchment = ee.Geometry.Polygon(catchment_shape['coordinates'])\n",
    "Map.addLayer(catchment, {}, 'Catchment')\n",
    "\n",
    "catchment_area = catchment.area().divide(1000*1000).getInfo()\n",
    "print(f\"Catchment area is {catchment_area} km²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a3b97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Determine glaciers in catchment area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0002a5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Find all glacier that are intersecting catchment area in RGI60 database (for area 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "catchment = gpd.read_file(output_gpkg, layer='catchment_orig')\n",
    "df_areas = gpd.read_file('https://www.glims.org/RGI/rgi60_files/00_rgi60_regions.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b998cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas = df_areas.set_crs('EPSG:4326',allow_override=True)\n",
    "catchment = catchment.to_crs('EPSG:4326')\n",
    "df_areas_catchment = gpd.sjoin(df_areas, catchment, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "if len(df_areas_catchment.index) == 0:\n",
    "    print('No area found for catchment')\n",
    "    area = None\n",
    "elif len(df_areas_catchment.index) == 1:\n",
    "    area = df_areas_catchment.iloc[0]['RGI_CODE']\n",
    "    print(f\"Catchment belongs to area {area} ({df_areas_catchment.iloc[0]['FULL_NAME']})\")\n",
    "else:\n",
    "    display(df_areas_catchment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2aa66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "if area != None:\n",
    "    url = \"https://www.glims.org/RGI/rgi60_files/\"  # Replace with the URL of your web server\n",
    "    html_page = urllib.request.urlopen(url)\n",
    "    html_content = html_page.read().decode(\"utf-8\")\n",
    "\n",
    "    # Use regular expressions to find links to files\n",
    "    pattern = re.compile(r'href=\"([^\"]+\\.zip)\"')\n",
    "    file_links = pattern.findall(html_content)\n",
    "\n",
    "\n",
    "    for file in file_links:\n",
    "        splits = file.split(\"_\")\n",
    "        if splits[0] != str(area): \n",
    "            continue\n",
    "\n",
    "        # starting scanning areas\n",
    "        areaname = splits[0] + \" (\" + splits[2].split(\".\")[0] + \")\"\n",
    "        print(f'scanning area {areaname}')\n",
    "\n",
    "        # read zip into dataframe\n",
    "        rgi = gpd.read_file(url+file)\n",
    "        if rgi.crs != catchment.crs:\n",
    "            print(\"CRS adjusted\")\n",
    "            catchment = catchment.to_crs(rgi.crs)\n",
    "\n",
    "        # check whether catchment intersects with glaciers of area\n",
    "        rgi_catchment = gpd.sjoin(rgi,catchment,how='inner',predicate='intersects')\n",
    "        if len(rgi_catchment.index) > 0:\n",
    "            print(f'{len(rgi_catchment.index)} outlines found in area {areaname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963cb30f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some glaciers do not belong to catchment but are intersecting the derived catchment area. Therefore, the percentage of the glacier will be calculated to determine whether glacier will be part of catchment or not (>=50% of its area needs to be in catchment). Glaciers outside catchment with overlapping area will reduce catchment area.\n",
    "Results for each glacier can be printed if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa61f85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# intersects selects too many. calculate percentage of glacier area that is within catchment\n",
    "rgi_catchment['rgi_area'] = rgi_catchment.area    \n",
    "    \n",
    "gdf_joined = gpd.overlay(catchment,rgi_catchment, how='union')\n",
    "gdf_joined['area_joined'] = gdf_joined.area\n",
    "gdf_joined['share_of_area'] = (gdf_joined['area_joined'] / gdf_joined['rgi_area'] * 100)\n",
    "\n",
    "results = (gdf_joined\n",
    "           .groupby(['RGIId','LABEL_1'])\n",
    "           .agg({'share_of_area':'sum'}))\n",
    "\n",
    "#print(results.sort_values(['share_of_area'],ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10ebba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rgi_catchment = pd.merge(rgi_catchment, results, on=\"RGIId\")\n",
    "rgi_in_catchment = rgi_catchment.loc[rgi_catchment['share_of_area'] >= 50]\n",
    "rgi_out_catchment = rgi_catchment.loc[rgi_catchment['share_of_area'] < 50]\n",
    "\n",
    "catchment_new = gpd.overlay(catchment, rgi_out_catchment, how='difference')\n",
    "catchment_new = gpd.overlay(catchment_new, rgi_in_catchment, how='union')\n",
    "catchment_new = catchment_new.dissolve()[['LABEL_1','geometry']]\n",
    "catchment_new['area'] = catchment_new.to_crs(\"+proj=cea +lat_0=35.68250088833567 +lon_0=139.7671 +units=m\")['geometry'].area\n",
    "area_glac = rgi_in_catchment.to_crs(\"+proj=cea +lat_0=35.68250088833567 +lon_0=139.7671 +units=m\")['geometry'].area\n",
    "area_glac = area_glac.sum()/1000000\n",
    "area_cat = catchment_new.iloc[0]['area']/1000000\n",
    "lat = catchment_new.centroid.y[0]\n",
    "print(f\"New catchment area is {area_cat} km²\")\n",
    "print(f\"Glacierized catchment area is {area_glac} km²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c36137",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Export data to existing geopackage:\n",
    "<ul>\n",
    "    <li>RGI glaciers within catchment</li>\n",
    "    <li>RGI glaciers outside catchment</li>\n",
    "    <li>Adjusted catchment area based in RGI glaciers</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c28a98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rgi_in_catchment.to_file(output_gpkg, layer='rgi_in', driver='GPKG')\n",
    "rgi_out_catchment.to_file(output_gpkg, layer='rgi_out', driver='GPKG')\n",
    "catchment_new.to_file(output_gpkg, layer='catchment_new', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f710c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Add determined glaciers and new catchment area to map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220513bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c_new = geemap.geopandas_to_ee(catchment_new)\n",
    "Map.addLayer(c_new, {'color': 'orange'}, \"Catchment New\")\n",
    "\n",
    "rgi = geemap.geopandas_to_ee(rgi_in_catchment)\n",
    "Map.addLayer(rgi, {'color': 'white'}, \"RGI60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39088d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_cat = image.reduceRegion(ee.Reducer.mean(),\n",
    "                          geometry=c_new).getInfo()['dem'] #['elevation']\n",
    "print(f\"Mean catchment elevation (adjusted) is {str(ele_cat)} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ee8f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The thickness of each glacier must be determined from raster files. Depending on the RGI IDs that are within catchment area, the corresponding raster files will be downloaded from server and stored in output folder.\n",
    "The thinkness raster files will be supported by DEM raster files for easier processing. They will also be extracted from a large zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8044058",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rgiids = rgi_in_catchment['RGIId'].sort_values()\n",
    "\n",
    "areas = []\n",
    "file_names_thickness = []\n",
    "file_names_dem = []\n",
    "for rgiid in rgiids:\n",
    "    # prepare filename that will be checked in *.zip archive in the next step\n",
    "    file_names_thickness.append(f'{rgiid}_thickness.tif')\n",
    "    file_names_dem.append(f'surface_DEM_{rgiid}.tif')\n",
    "    area = rgiid.split('.')[0]\n",
    "    if area not in areas: areas.append(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065e647",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Retrieve raster files for thickness and corresponding DEM raster files\n",
    "\n",
    "Start with thinkness: download from server and extract tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3a15b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "import os\n",
    "\n",
    "# download and extract thinkness raster files from server\n",
    "cnt_thickness = 0\n",
    "for area in areas:\n",
    "    url = f'https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/315707/composite_thickness_{area}.zip?sequence=15&isAllowed=y'\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    with ZipFile(io.BytesIO(r.content), 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        for fileName in listOfFileNames:\n",
    "            file = fileName.split('/')[1]\n",
    "            if file in file_names_thickness:\n",
    "                cnt_thickness += 1\n",
    "                zipObj.extract(fileName, output_folder+'RGI')\n",
    "print(f'{cnt_thickness} files have been extracted (ice thickness)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55153b75",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try to download DEM archive from server. Since archive has large file size, it might be uploaded manually. The download must be activated in <code>config.ini</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4436fe3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if(download_rgi_dem):\n",
    "    print(\"Downloading file...\")\n",
    "    \n",
    "    if area == 'RGI60-13':\n",
    "        # try to get DEM from server (large file size (560 MB), might take some time)\n",
    "        url = 'https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/315707/surface_DEMs_RGI60-13.zip?sequence=70&isAllowed=y'\n",
    "        \n",
    "        # Download the zip file from the URL\n",
    "        response = urllib.request.urlopen(url)\n",
    "        filename = os.path.basename(url).split('?')[0]\n",
    "        \n",
    "        # Save the zip file to the output folder\n",
    "        local_file_path = output_folder + filename\n",
    "        with open(local_file_path, \"wb\") as local_file:\n",
    "            local_file.write(response.read())\n",
    "    else:\n",
    "        # try to get DEM from server (very large file size (2.8 GB), might take some time)\n",
    "        url = f'https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/315707/surface_DEMs_RGI60.zip?sequence=65&isAllowed=y'\n",
    "        r = requests.get(url, stream=True)\n",
    "\n",
    "        with ZipFile(io.BytesIO(r.content), 'r') as zipObj:\n",
    "            # Get a list of all archived file names from the zip\n",
    "            listOfFileNames = zipObj.namelist()\n",
    "            for area in areas:\n",
    "                fileName = f'surface_DEMs_{area}.zip'\n",
    "                if fileName in listOfFileNames:\n",
    "                    zipObj.extract(fileName, output_folder)\n",
    "                else:\n",
    "                    print(f'No DEM archive found for area {area}') \n",
    "else:\n",
    "    print(\"No file download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd642c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Extract DEM tif files from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbc118",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extract DEM raster files from archive (previously downloaded or uploaded)\n",
    "cnt_dem = 0\n",
    "for area in areas:\n",
    "    with ZipFile(output_folder + f'surface_DEMs_{area}.zip', 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        for fileName in listOfFileNames:\n",
    "            if fileName in file_names_dem:\n",
    "                cnt_dem += 1\n",
    "                zipObj.extract(fileName, output_folder+'RGI/DEM/')\n",
    "print(f'{cnt_dem} files have been extracted (DEM)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb279f3a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Glacier profile creation\n",
    "Overlay ice thickness and DEM tif for each glacier to create tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8286f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "if cnt_thickness != cnt_dem:\n",
    "    print('Number of thickness raster files does not match number of DEM raster files!')\n",
    "else:\n",
    "    for idx,rgiid in enumerate(rgiids):\n",
    "        if rgiid in file_names_thickness[idx] and rgiid in file_names_dem[idx]:\n",
    "            file_list = [\n",
    "                output_folder + 'RGI/RGI60-13/' + file_names_thickness[idx],\n",
    "                output_folder + 'RGI/DEM/' + file_names_dem[idx]\n",
    "            ]\n",
    "            array_list = []\n",
    "\n",
    "            # Read arrays\n",
    "            for file in file_list:\n",
    "                src = gdal.Open(file)\n",
    "                geotransform = src.GetGeoTransform() # Could be done more elegantly outside the for loop\n",
    "                projection = src.GetProjectionRef()\n",
    "                array_list.append(src.ReadAsArray())\n",
    "                pixelSizeX = geotransform[1]\n",
    "                pixelSizeY =-geotransform[5]                \n",
    "                src = None\n",
    "            \n",
    "            df = pd.DataFrame()\n",
    "            df['thickness'] = array_list[0].flatten()\n",
    "            df['altitude'] = array_list[1].flatten()\n",
    "            df_all = df_all.append(df)\n",
    "        else:\n",
    "            print(f'Raster files do not match for {rgiid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b91bc2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Remove all points with zero ice thickness and aggregate all points to 10m elevation zones.\n",
    "\n",
    "Export result as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46872d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(df_all) > 0:\n",
    "    df_all = df_all.loc[df_all['thickness'] > 0]\n",
    "    df_all.sort_values(by=['altitude'],inplace=True)\n",
    "    \n",
    "    # get min/max altitude considering catchment and all glaciers\n",
    "    alt_min = 10*int(min(catchment_bounds[0],df_all['altitude'].min())/10)\n",
    "    alt_max = max(catchment_bounds[1],df_all['altitude'].max())+10\n",
    "        \n",
    "    # create bins in 10m steps\n",
    "    bins = np.arange(alt_min, df_all['altitude'].max()+10, 10)\n",
    "    \n",
    "    # aggregate per bin and do some math\n",
    "    df_agg = df_all.groupby(pd.cut(df_all['altitude'], bins))['thickness'].agg(count='size', mean='mean').reset_index()\n",
    "    df_agg['Elevation'] = df_agg['altitude'].apply(lambda x: x.left)\n",
    "    df_agg['Area'] = df_agg['count']*pixelSizeX*pixelSizeY / catchment_new.iloc[0]['area']\n",
    "    df_agg['WE'] = df_agg['mean']*0.908*1000\n",
    "    df_agg['EleZone'] = df_agg['Elevation'].apply(lambda x: 100*int(x/100))\n",
    "    \n",
    "    # delete empty elevation bands but keep at least one entry per elevation zone\n",
    "    df_agg=pd.concat([df_agg.loc[df_agg['count']>0],\n",
    "                      df_agg.loc[df_agg['count']==0].drop_duplicates(['EleZone'],keep='first')]\n",
    "                    ).sort_index()\n",
    "    \n",
    "    df_agg.drop(['altitude', 'count', 'mean'], axis=1, inplace=True)\n",
    "    df_agg.fillna(0, inplace=True)\n",
    "    df_agg.to_csv(output_folder + 'glacier_profile.csv', header=True, index=False)\n",
    "    print('Glacier profile for catchment successfully created !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bfc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele_glac = round(df_all.altitude.mean(), 2)\n",
    "print(f'Average glacier elevation in the catchment: {ele_glac} m.a.s.l.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07b15b",
   "metadata": {},
   "source": [
    "Create a settings.yaml and store the relevant catchment information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "settings = {'area_cat': float(area_cat),\n",
    "            'ele_cat': float(ele_cat),\n",
    "            'area_glac': float(area_glac),\n",
    "            'ele_glac': float(ele_glac),\n",
    "            'lat': float(lat),\n",
    "            'glacier_profile': output_folder + 'glacier_profile.csv'\n",
    "           }\n",
    "with open(output_folder + 'settings.yml', 'w') as f:\n",
    "    yaml.safe_dump(settings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f10c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
