{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58bb595d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf387a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Google Earth Engine packages\n",
    "import ee\n",
    "import geemap\n",
    "import geemap.colormaps as cm\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# function to load nc file into GEE\n",
    "def netcdf_to_ee(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    data = ds['z']\n",
    "\n",
    "    lon_data = np.round(data['lon'], 3)\n",
    "    lat_data = np.round(data['lat'], 3)\n",
    "\n",
    "    dim_lon = np.unique(np.ediff1d(lon_data).round(3))\n",
    "    dim_lat = np.unique(np.ediff1d(lat_data).round(3))\n",
    "\n",
    "    if (len(dim_lon) != 1) or (len(dim_lat) != 1):\n",
    "        print(\"The netCDF file is not a regular longitude/latitude grid\")\n",
    "\n",
    "    data_np = np.array(data)\n",
    "    data_np = np.transpose(data_np)\n",
    "\n",
    "    # Figure out if we need to roll the data or not\n",
    "    # (see https://github.com/giswqs/geemap/issues/285#issuecomment-791385176)\n",
    "    if np.max(lon_data) > 180:\n",
    "        data_np = np.roll(data_np, 180, axis=0)\n",
    "        west_lon = lon_data[0] - 180\n",
    "    else:\n",
    "        west_lon = lon_data[0]\n",
    "\n",
    "    transform = [dim_lon[0], 0, float(west_lon) - dim_lon[0]/2, 0, dim_lat[0], float(lat_data[0]) - dim_lat[0]/2]\n",
    "\n",
    "    image = geemap.numpy_to_ee(\n",
    "        data_np, \"EPSG:4326\", transform=transform, band_names='z'\n",
    "    )\n",
    "    return image, data_np, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa4d33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize GEE at the beginning of session\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()         # authenticate when using GEE for the first time\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e1a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import ast\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# get file config from config.ini\n",
    "dir_input = config['FILE_SETTINGS']['DIR_INPUT']\n",
    "dir_output = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "output_gpkg = dir_output + config['FILE_SETTINGS']['GPKG_NAME']\n",
    "scenarios = config.getboolean('CONFIG', 'PROJECTIONS')\n",
    "show_map = config.getboolean('CONFIG','SHOW_MAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbdbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_map:\n",
    "    Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48dd59-8db9-4d75-b006-bb0e20868252",
   "metadata": {},
   "source": [
    "# Configure the downloaded date range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf271a2-21a8-4640-b728-4fd77d5b89d7",
   "metadata": {},
   "source": [
    "If you are only interested in modeling the past, set `PROJECTIONS=False` in the `config.ini` to download reanalysis data for your defined modeling period only. Otherwise, all available historic data (since 1979) is downloaded to provide the best possible basis for bias adjustment of the climate scenario data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef695f6-869a-49ce-b36b-36e99170e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenarios == True:\n",
    "    date_range = ['1979-01-01', '2022-01-01']\n",
    "else:\n",
    "    date_range = ast.literal_eval(config['CONFIG']['DATE_RANGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac1d9e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661570c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ERA5L Geopotential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb5161",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e70f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load ERA5L file for geopotential and add to Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa6009",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = 'ERA5_land_Z_geopotential_HMA.nc'\n",
    "filename = dir_input + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94beda1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image, data_np, transform = netcdf_to_ee(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ffde1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if show_map:\n",
    "    # add image as layer\n",
    "    vis_params =  {'min': int(data_np.min()), 'max': int(data_np.max()), 'palette': cm.palettes.terrain, 'opacity': 0.8}\n",
    "    Map.addLayer(image, vis_params, \"ERA5L geopotential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08097b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load catchment and add to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91f543",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "catchment_new = gpd.read_file(output_gpkg, layer='catchment_new')\n",
    "catchment = geemap.geopandas_to_ee(catchment_new)\n",
    "\n",
    "if show_map:\n",
    "    Map.addLayer(catchment, {'color': 'darkgrey'}, \"Catchment\")\n",
    "    Map.centerObject(catchment, zoom=9)\n",
    "    display(Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa96058",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate weighted average geopotential and convert to elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cef7a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# execute reducer\n",
    "dict = image.reduceRegion(ee.Reducer.mean(),\n",
    "                          geometry=catchment,\n",
    "                          crs='EPSG:4326',\n",
    "                          crsTransform=transform)\n",
    "\n",
    "# get mean value and print\n",
    "mean_val = dict.getInfo()['z']\n",
    "ele_dat = mean_val / 9.80665\n",
    "print(f'geopotential mean: {mean_val:.2f}, elevation: {ele_dat:.2f}m.a.s.l.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d733730",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76974de1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ERA5L Temperature and Precipitation Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80281587",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def setProperty(image):\n",
    "    dict = image.reduceRegion(ee.Reducer.mean(), catchment)\n",
    "    return image.set(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388dfee6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "collection = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_RAW')\\\n",
    "    .select('temperature_2m','total_precipitation_sum')\\\n",
    "    .filterDate(date_range[0], date_range[1])\n",
    "\n",
    "withMean = collection.map(setProperty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ce230",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['ts'] = withMean.aggregate_array('system:time_start').getInfo()\n",
    "df['temp'] = withMean.aggregate_array('temperature_2m').getInfo()\n",
    "df['temp_c'] = df['temp'] - 273.15\n",
    "df['prec'] = withMean.aggregate_array('total_precipitation_sum').getInfo()\n",
    "df['prec'] = df['prec'] * 1000\n",
    "df['dt'] = df['ts'].apply(lambda x: datetime.datetime.fromtimestamp(x / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934aac84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(dir_output + 'ERA5L.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7b7cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef333ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Append data reference elevation to settings.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def read_yaml(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "        return data\n",
    "    \n",
    "def write_yaml(data, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        yaml.safe_dump(data, f)\n",
    "\n",
    "def update_yaml(file_path, new_items):\n",
    "    data = read_yaml(file_path)\n",
    "    data.update(new_items)\n",
    "    write_yaml(data, file_path)\n",
    "\n",
    "        \n",
    "update_yaml(dir_output + 'settings.yml', {'ele_dat': float(ele_dat)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8199c",
   "metadata": {},
   "source": [
    "# Alternative ERA5 Routine (parallele Tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import requests\n",
    "from retry import retry\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ERA5Downloader:\n",
    "    \"\"\"Class to download ERA5 data for a given period, variable, and spatial subset.\"\"\"\n",
    "\n",
    "    def __init__(self, var, starty, endy, shape, processes=10, dir='./'):\n",
    "        self.var = var\n",
    "        self.starty = starty\n",
    "        self.endy = endy\n",
    "        self.shape = shape\n",
    "        self.processes = processes\n",
    "    \n",
    "    def download(self):\n",
    "        \"\"\"Runs a subset routine for ERA5 data on GEE servers to create ee.ImageCollections for all years in\n",
    "        the requested period. Downloads individual years in parallel processes to increase the download time.\"\"\"\n",
    "\n",
    "        def getRequests(starty, endy):\n",
    "            \"\"\"Generates a list of years to be downloaded. [Client side]\"\"\"\n",
    "\n",
    "            return [i for i in range(starty, endy+1)]\n",
    "        \n",
    "        @retry(tries=10, delay=1, backoff=2)\n",
    "        def getResult(index, year):\n",
    "            \"\"\"Handle the HTTP requests to download one year of CMIP6 data. [Server side]\"\"\"\n",
    "\n",
    "            start = str(year) + '-01-01'\n",
    "            end = str(year + 1) + '-01-01'\n",
    "            startDate = ee.Date(start)\n",
    "            endDate = ee.Date(end)\n",
    "            n = endDate.difference(startDate, 'day').subtract(1)\n",
    "            \n",
    "            def getImageCollection(var):\n",
    "                \"\"\"Create and image collection of CMIP6 data for the requested variable, period, and region.\n",
    "                [Server side]\"\"\"\n",
    "\n",
    "                collection = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_RAW') \\\n",
    "                    .select(var) \\\n",
    "                    .filterDate(startDate, endDate)\n",
    "                return collection\n",
    "            \n",
    "            def renameBandName(b):\n",
    "                \"\"\"Edit variable names for better readability. [Server side]\"\"\"\n",
    "\n",
    "                split = ee.String(b).split('_')\n",
    "                return ee.String(split.splice(0, 1).join(\"_\"))\n",
    "\n",
    "            def buildFeature(i):\n",
    "                \"\"\"Create an area weighted average of the defined region for every day in the given year.\n",
    "                [Server side]\"\"\"\n",
    "\n",
    "                t1 = startDate.advance(i, 'day')\n",
    "                t2 = t1.advance(1, 'day')\n",
    "                # feature = ee.Feature(point)\n",
    "                dailyColl = collection.filterDate(t1, t2)\n",
    "                dailyImg = dailyColl.toBands()\n",
    "                # renaming and handling names\n",
    "                bands = dailyImg.bandNames()\n",
    "                renamed = bands.map(renameBandName)\n",
    "                # Daily extraction and adding time information\n",
    "                dict = dailyImg.rename(renamed).reduceRegion(\n",
    "                    reducer=ee.Reducer.mean(),\n",
    "                    geometry=self.shape,\n",
    "                ).combine(\n",
    "                    ee.Dictionary({'system:time_start': t1.millis(), 'isodate': t1.format('YYYY-MM-dd')})\n",
    "                )\n",
    "                return ee.Feature(None, dict)\n",
    "            \n",
    "            # Create features for all days in the respective year. [Server side]\n",
    "            collection = getImageCollection(self.var)\n",
    "            year_feature = ee.FeatureCollection(ee.List.sequence(0, n).map(buildFeature))\n",
    "\n",
    "            # Create a download URL for a CSV containing the feature collection. [Server side]\n",
    "            url = year_feature.getDownloadURL()\n",
    "\n",
    "            # Handle downloading the actual csv for one year. [Client side]\n",
    "            r = requests.get(url, stream=True)\n",
    "            if r.status_code != 200:\n",
    "                r.raise_for_status()\n",
    "            filename = 'output/ERA5/era5_' + self.var + '_' + str(year) + '.csv'\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write(r.text)\n",
    "            \n",
    "            return index\n",
    "            \n",
    "        # Create a list of years to be downloaded. [Client side]\n",
    "        items = getRequests(self.starty, self.endy)\n",
    "\n",
    "        # Launch download requests in parallel processes and display a status bar. [Client side]\n",
    "        with tqdm(total=len(items), desc=\"Downloading ERA5 data for variable '\" + self.var + \"'\") as pbar:\n",
    "            results = []\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=self.processes) as executor:\n",
    "                for i, year in enumerate(items):\n",
    "                    results.append(executor.submit(getResult, i, year))\n",
    "                for future in concurrent.futures.as_completed(results):\n",
    "                    index = future.result()\n",
    "                    pbar.update(1)\n",
    "\n",
    "        print(\"All downloads complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader_t = ERA5Downloader('temperature_2m', 1979, 2021, catchment, processes=25)\n",
    "downloader_t.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36197791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aecd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
